{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NontapornWong/HW_NLP5_MusicGen-GPT/blob/main/MuGenTransformer_v3_stable_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4-8gG122yTC"
      },
      "source": [
        "## V3\n",
        "V1\n",
        "- custom generator\n",
        "- to load random sequence from each batch\n",
        "- Result is very positive :D\n",
        "-----\n",
        "V2\n",
        "- Testing out for different preprocess data type: 100f data\n",
        "- After 6000 epoches, the results seem to be quite positive, although the data takes quite long to generate\n",
        "- Unfortunately, the model overfitted very badly. \n",
        "- Also tested with different encoding method. However, model performed really badly.thus thus was the end of v2\n",
        "-----\n",
        "V3\n",
        "- revert back to v1 with modification.\n",
        "- will include tags: < UNK >, < PAD >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kkk3XW3p_Vl",
        "outputId": "b134ef7e-9fe2-4fbb-cd67-5f70d640b260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.10/dist-packages (8.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from music21) (4.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from music21) (1.2.0)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.10/dist-packages (from music21) (3.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from music21) (3.7.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from music21) (9.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from music21) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from music21) (2.27.1)\n",
            "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.10/dist-packages (from music21) (1.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->music21) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->music21) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mido\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.22.4)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Building wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=c0f74c5f50f118f52e0bdd564ff13b88692fb43bd65e770f6ffa987a1f526642\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: pretty_midi\n",
            "Successfully installed pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "!pip install music21\n",
        "!pip install mido\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9EKCYrv-Y2v",
        "outputId": "6ee2c89b-139d-471e-c7ed-249c9371c1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iw9iWCXjLhJ"
      },
      "source": [
        "### Import module and define path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0dfe-nxqbWl"
      },
      "outputs": [],
      "source": [
        "import pretty_midi\n",
        "from music21 import *\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "from itertools import groupby\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "# from keras.preprocessing import sequence\n",
        "# from keras.models import Sequential \n",
        "# from keras.layers import Dense, LSTM, Bidirectional, Dropout, GlobalMaxPooling1D, Activation, GlobalMaxPooling2D\n",
        "# from keras_self_attention import SeqSelfAttention\n",
        "# from keras.utils import to_categorical\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "# from keras.layers import Layer\n",
        "# from tensorflow.python.client import device_lib\n",
        "# import keras\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit([np.arange(128).tolist()])\n",
        "\n",
        "# data_path = \"./selected_data/\"\n",
        "# data_path = \"./doug_mckenzie_midi/\"\n",
        "# data_path = \"./sample_data/\"\n",
        "# encoded_data_path = \"./data/encoded_doug_mckenzie_midi_100f/\"\n",
        "encoded_data_path = \"/content/drive/MyDrive/5 - Music Generation by GPT/encoded_doug_mckenzie_midi_16_v2/\"\n",
        "# encoded_data_path = \"../data/encoded_doug_mckenzie_midi_32_v2/\"\n",
        "# encoded_data_path = \"./data/encoded_doug_mckenzie_midi_32/\"\n",
        "output_path = \"/content/drive/MyDrive/5 - Music Generation by GPT/output/\"\n",
        "\n",
        "batch_size = 32\n",
        "# sequence_length = 500\n",
        "sequence_length = 600\n",
        "generate_sample_every_ep = 100\n",
        "\n",
        "maxlen = sequence_length  # Max sequence size\n",
        "# embed_dim = 128  # Embedding size for each token\n",
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "feed_forward_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "combi_to_int_pickle = \"combi_to_int.pickle\"\n",
        "int_to_combi_pickle = \"int_to_combi.pickle\"\n",
        "vocab_pickle = \"vocab.pickle\"\n",
        "\n",
        "# vocab_size = 50000\n",
        "vocab_size = 40000\n",
        "unk_tag_str = '<UNK>'\n",
        "unk_tag_idx = 0\n",
        "pad_tag_str = ''\n",
        "pad_tag_idx = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_file_path = \"/content/drive/MyDrive/5 - Music Generation by GPT/encoded_doug_mckenzie_midi_16_v2.zip\"\n",
        "unzip_directory = \"/content/drive/MyDrive/5 - Music Generation by GPT/encoded_doug_mckenzie_midi_16_v2/\"\n",
        "\n",
        "# Check if the zip file exists\n",
        "if os.path.isfile(zip_file_path):\n",
        "    print(\"Zip file exists.\")\n",
        "\n",
        "    # Check if the unzip directory exists\n",
        "    if not os.path.isdir(unzip_directory):\n",
        "        # Create the unzip directory if it doesn't exist\n",
        "        os.makedirs(unzip_directory)\n",
        "        print(\"Unzip directory created.\")\n",
        "\n",
        "    # Extract the contents of the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(unzip_directory)\n",
        "    print(\"Zip file extracted successfully.\")\n",
        "else:\n",
        "    print(\"Zip file does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAoox8w7sKEG",
        "outputId": "a67b07bf-0866-4517-afef-9f479711bd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file exists.\n",
            "Unzip directory created.\n",
            "Zip file extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/5 - Music Generation by GPT/encoded_doug_mckenzie_midi_16_v2/encoded_doug_mckenzie_midi_16_v2/\"\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.isdir(folder_path):\n",
        "    print(\"Folder exists.\")\n",
        "\n",
        "    # List files in the folder\n",
        "    file_list = os.listdir(folder_path)\n",
        "    if len(file_list) > 0:\n",
        "        print(\"Files in the folder:\")\n",
        "        for file_name in file_list:\n",
        "            print(file_name)\n",
        "    else:\n",
        "        print(\"No files found in the folder.\")\n",
        "else:\n",
        "    print(\"Folder does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWiaL-otVY9",
        "outputId": "1a7230b6-d576-4c50-f545-030d63b4487b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder exists.\n",
            "Files in the folder:\n",
            "encoded_ABeautifulFriendship.npy\n",
            "encoded_AChildIsBorn2.npy\n",
            "encoded_AFineRomance.npy\n",
            "encoded_AHouseisNot.npy\n",
            "encoded_ARemark.npy\n",
            "encoded_ASleepinBee.npy\n",
            "encoded_Aghostofachance.npy\n",
            "encoded_AllTheThingsGroup.npy\n",
            "encoded_AllTheThingssoloandtrio.npy\n",
            "encoded_AlmostBlue.npy\n",
            "encoded_AloneTogether.npy\n",
            "encoded_AnAffairToRemember.npy\n",
            "encoded_AngelEyes.npy\n",
            "encoded_Answer%20me%20My%20LoveCorrected2.npy\n",
            "encoded_ArmandosRumba.npy\n",
            "encoded_AutumnLeaves%5b1%5d.npy\n",
            "encoded_AveMaria.npy\n",
            "encoded_BaublesRubato.npy\n",
            "encoded_BeautifulLove.npy\n",
            "encoded_BessYouIsPart1.npy\n",
            "encoded_Blackbird(GM).npy\n",
            "encoded_Blackbird(XG).npy\n",
            "encoded_BlueBossa1GM.npy\n",
            "encoded_BlueBossa1XG.npy\n",
            "encoded_BlueBossa3GM.npy\n",
            "encoded_BlueBossa3XG.npy\n",
            "encoded_BoyNextDoor.npy\n",
            "encoded_ButBeautiful.npy\n",
            "encoded_Caravan1.npy\n",
            "encoded_Carnival%5b2b%5d.npy\n",
            "encoded_ChelseaBridge.npy\n",
            "encoded_ChopinWaltzAb.npy\n",
            "encoded_Clifford1.npy\n",
            "encoded_Clifford2.npy\n",
            "encoded_CloseEnoughForLovePart1.npy\n",
            "encoded_CloseEnoughForLovePart2.npy\n",
            "encoded_Cryme.npy\n",
            "encoded_DancingInTheDark.npy\n",
            "encoded_DancingOnTheCeiling.npy\n",
            "encoded_Dannyboy.npy\n",
            "encoded_DarnThatDream.npy\n",
            "encoded_DayDream.npy\n",
            "encoded_DaysofWine.npy\n",
            "encoded_DeepPurple.npy\n",
            "encoded_DetourAhead.npy\n",
            "encoded_EastOfTheSun.npy\n",
            "encoded_Easy%20Living%203.npy\n",
            "encoded_EasyDoesIt.npy\n",
            "encoded_Effendi%20-%20McCoy%20Tyner.npy\n",
            "encoded_Eleanor.npy\n",
            "encoded_EleanorRigby.npy\n",
            "encoded_Embraceable.npy\n",
            "encoded_FarAwayPlaces.npy\n",
            "encoded_FlyMeToTheMoon.npy\n",
            "encoded_ForAllWe2.npy\n",
            "encoded_Georgia.npy\n",
            "encoded_GirlTalk.npy\n",
            "encoded_GodBlessTheChildPianoAccompany.npy\n",
            "encoded_GoneWithTheWind2.npy\n",
            "encoded_GoodBaitPiano.npy\n",
            "encoded_Goodbye.npy\n",
            "encoded_Gymnopedie-It%20Never%20Entered%20My%20Mind.npy\n",
            "encoded_HeatherOnTheHill(Part1).npy\n",
            "encoded_HeatherOnTheHill(Part2).npy\n",
            "encoded_HiLiliCombined.npy\n",
            "encoded_I'mOldFash.npy\n",
            "encoded_IConcentrate.npy\n",
            "encoded_IFallInLove.npy\n",
            "encoded_IHearaRhapsody.npy\n",
            "encoded_IMustHaveThatman.npy\n",
            "encoded_IWishYouLove.npy\n",
            "encoded_Icantgetstarted.npy\n",
            "encoded_IfIShouldLoseYou.npy\n",
            "encoded_IllBeSeeGMversion.npy\n",
            "encoded_IllBeSeeXGversion.npy\n",
            "encoded_ImConfessin.npy\n",
            "encoded_ImInTheMoodForLove.npy\n",
            "encoded_ImThroughWithLove.npy\n",
            "encoded_InTheWeeSmallHoursOfTheMorning.npy\n",
            "encoded_Irememberyousolo.npy\n",
            "encoded_ItCouldHappenGM.npy\n",
            "encoded_ItCouldHappenXG.npy\n",
            "encoded_ItMightAsWellBeSpringSolo.npy\n",
            "encoded_IveGotACrushOnYou.npy\n",
            "encoded_IveGotTheWorldOnAString.npy\n",
            "encoded_IveGrown.npy\n",
            "encoded_IveNeverBeen.npy\n",
            "encoded_JustALittle3.npy\n",
            "encoded_JustOneOfThoseThingsSolo.npy\n",
            "encoded_JustOneOfThoseThingsTrio.npy\n",
            "encoded_Laura.npy\n",
            "encoded_LesGrelots.npy\n",
            "encoded_LetItSnow.npy\n",
            "encoded_LittleGirlBlue.npy\n",
            "encoded_LoveIsAManySplendoredThing.npy\n",
            "encoded_LoveWalked.npy\n",
            "encoded_LoveYouMadlyCorrected.npy\n",
            "encoded_LushLife.npy\n",
            "encoded_Manhattan.npy\n",
            "encoded_MeanToMe.npy\n",
            "encoded_MemoriesOfYou.npy\n",
            "encoded_MemoriesofParis.npy\n",
            "encoded_Misty5GM.npy\n",
            "encoded_Misty5XG.npy\n",
            "encoded_MonaLisa.npy\n",
            "encoded_MoonRiver3.npy\n",
            "encoded_MoonlightInVermont.npy\n",
            "encoded_MoreThanYou.npy\n",
            "encoded_MyFoolish.npy\n",
            "encoded_MyRomanceGM.npy\n",
            "encoded_MyRomanceXG.npy\n",
            "encoded_MyShiningGroup.npy\n",
            "encoded_MyShiningSolo.npy\n",
            "encoded_MyShip.npy\n",
            "encoded_NatureBoyRubato.npy\n",
            "encoded_NeverLetMe.npy\n",
            "encoded_OklahomaMedley.npy\n",
            "encoded_OldFolks.npy\n",
            "encoded_OneForMyBaby.npy\n",
            "encoded_Out%20of%20Nowhere%201.npy\n",
            "encoded_OverTheRainbowGM.npy\n",
            "encoded_OverTheRainbowV2ForXG.npy\n",
            "encoded_OverTheRainbowXG.npy\n",
            "encoded_Pathetique.npy\n",
            "encoded_PeanutVendor.npy\n",
            "encoded_Rainwalt.npy\n",
            "encoded_RedDress2.npy\n",
            "encoded_RoundMidnight2Corrected.npy\n",
            "encoded_SammyWalked.npy\n",
            "encoded_SatinDoll.npy\n",
            "encoded_SaveYourLoveForMe.npy\n",
            "encoded_SeptemberInTheRain.npy\n",
            "encoded_She'sLeaving.npy\n",
            "encoded_Shenandoah.npy\n",
            "encoded_ShesFunnyThatWay.npy\n",
            "encoded_SmallDay.npy\n",
            "encoded_SmokeGetsInYourEyes.npy\n",
            "encoded_Solitude.npy\n",
            "encoded_SomeOtherTime.npy\n",
            "encoded_Sometimeago.npy\n",
            "encoded_Sonnymoon10.npy\n",
            "encoded_Spain4.npy\n",
            "encoded_SpeakLow.npy\n",
            "encoded_StarsFellOnAlabama.npy\n",
            "encoded_Stella.npy\n",
            "encoded_Strollin.npy\n",
            "encoded_SunnySide.npy\n",
            "encoded_SurreyVocal.npy\n",
            "encoded_Sweet1.npy\n",
            "encoded_SweetLorraine1.npy\n",
            "encoded_SweetWay1.npy\n",
            "encoded_SweetWay2.npy\n",
            "encoded_SweetWay3.npy\n",
            "encoded_TheMoreISeeYou.npy\n",
            "encoded_TheShadowOfYourSmile.npy\n",
            "encoded_TheSongisYoutrio.npy\n",
            "encoded_ThereWillNeverBe.npy\n",
            "encoded_TheseFoolish.npy\n",
            "encoded_Thingsaint.npy\n",
            "encoded_ThisNearlyWasMine.npy\n",
            "encoded_Time%20after%20Time%202.npy\n",
            "encoded_Tryalittle21.npy\n",
            "encoded_TwoForTheRoad.npy\n",
            "encoded_VeryEarly.npy\n",
            "encoded_WhatIsThereToSay.npy\n",
            "encoded_WhoCanITurnTo.npy\n",
            "encoded_WhyDoILoveYou.npy\n",
            "encoded_WildIsTheWind.npy\n",
            "encoded_Witchcraft.npy\n",
            "encoded_WrapYourTroublesInDreams.npy\n",
            "encoded_Yesterdays1.npy\n",
            "encoded_YouAndTheNightAndTheMusicRubato.npy\n",
            "encoded_YouAndTheNightAndTheMusicTrio.npy\n",
            "encoded_YouAreTooBeautiful.npy\n",
            "encoded_YouMustBelieveInSpringall.npy\n",
            "encoded_YoudBeSoNiceToComeHomeTo.npy\n",
            "encoded_YoullNeverKnow.npy\n",
            "encoded_atimeforlove.npy\n",
            "encoded_cinema%208.npy\n",
            "encoded_goodbaitGM.npy\n",
            "encoded_justyou.npy\n",
            "encoded_porgy1.npy\n",
            "encoded_porgy2.npy\n",
            "encoded_simplelife.npy\n",
            "encoded_sophisticated.npy\n",
            "encoded_taketheatrain.npy\n",
            "encoded_touchv4.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY848lUWznQ2"
      },
      "source": [
        "## Preprocess Data\n",
        "In order to carry out this step you need to unzip the encoded_doug_mckenzie_midi_16_v2.zip. Or you can just import all the varibales from the pickle files in the import step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og1gG5GvzpbK"
      },
      "outputs": [],
      "source": [
        "# all_songs = []\n",
        "# # all_song_in_tuple = []\n",
        "# all_songs_np = np.empty((0,128), np.int8)\n",
        "# for temp in glob.glob(encoded_data_path + \"*.npy\"):\n",
        "#     encoded_data = np.load(temp).astype(np.int8)\n",
        "#     all_songs.append(encoded_data)\n",
        "#     all_songs_np = np.append(all_songs_np, encoded_data, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_songs = []\n",
        "# all_song_in_tuple = []\n",
        "all_songs_np = np.empty((0,128), np.int8)\n",
        "for temp in glob.glob(folder_path + \"*.npy\"):\n",
        "    encoded_data = np.load(temp).astype(np.int8)\n",
        "    all_songs.append(encoded_data)\n",
        "    all_songs_np = np.append(all_songs_np, encoded_data, axis=0)"
      ],
      "metadata": {
        "id": "HmVXxSt7viFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for song in all_songs:\n",
        "    print(len(song))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTyN1Anhvtx6",
        "outputId": "08e60238-7c56-4690-ff01-be95bdb0601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "796\n",
            "893\n",
            "1556\n",
            "2550\n",
            "1277\n",
            "1181\n",
            "2840\n",
            "2645\n",
            "1074\n",
            "2375\n",
            "2163\n",
            "1406\n",
            "1157\n",
            "2205\n",
            "1085\n",
            "3706\n",
            "2548\n",
            "904\n",
            "4190\n",
            "677\n",
            "1471\n",
            "1471\n",
            "1248\n",
            "1248\n",
            "2134\n",
            "2134\n",
            "1261\n",
            "2148\n",
            "4435\n",
            "2059\n",
            "1835\n",
            "2354\n",
            "1595\n",
            "1250\n",
            "884\n",
            "1038\n",
            "2444\n",
            "1614\n",
            "1290\n",
            "1902\n",
            "1001\n",
            "1881\n",
            "2690\n",
            "2056\n",
            "706\n",
            "1298\n",
            "1120\n",
            "2307\n",
            "1834\n",
            "2006\n",
            "903\n",
            "2179\n",
            "920\n",
            "1211\n",
            "2088\n",
            "2480\n",
            "1816\n",
            "1139\n",
            "2648\n",
            "2563\n",
            "775\n",
            "1501\n",
            "748\n",
            "653\n",
            "2304\n",
            "1973\n",
            "945\n",
            "2029\n",
            "3657\n",
            "1263\n",
            "1381\n",
            "1640\n",
            "2511\n",
            "2494\n",
            "2494\n",
            "435\n",
            "867\n",
            "1954\n",
            "2692\n",
            "4639\n",
            "2972\n",
            "2972\n",
            "2114\n",
            "5563\n",
            "387\n",
            "2083\n",
            "1619\n",
            "1034\n",
            "326\n",
            "2047\n",
            "2922\n",
            "2580\n",
            "1203\n",
            "1568\n",
            "455\n",
            "1847\n",
            "1409\n",
            "3039\n",
            "2545\n",
            "3178\n",
            "2194\n",
            "993\n",
            "1581\n",
            "1581\n",
            "1137\n",
            "1057\n",
            "2103\n",
            "1284\n",
            "3912\n",
            "3415\n",
            "3416\n",
            "2285\n",
            "1489\n",
            "1300\n",
            "755\n",
            "876\n",
            "4071\n",
            "1953\n",
            "2143\n",
            "2625\n",
            "1802\n",
            "3181\n",
            "1802\n",
            "2451\n",
            "3015\n",
            "2751\n",
            "821\n",
            "1023\n",
            "1838\n",
            "2085\n",
            "709\n",
            "661\n",
            "1501\n",
            "533\n",
            "785\n",
            "1342\n",
            "645\n",
            "2097\n",
            "1676\n",
            "2489\n",
            "2173\n",
            "5266\n",
            "2901\n",
            "618\n",
            "761\n",
            "1681\n",
            "918\n",
            "3251\n",
            "1723\n",
            "1224\n",
            "2249\n",
            "1683\n",
            "1139\n",
            "2137\n",
            "3670\n",
            "3262\n",
            "2672\n",
            "1549\n",
            "2748\n",
            "2467\n",
            "1888\n",
            "1646\n",
            "3148\n",
            "1293\n",
            "1606\n",
            "1901\n",
            "1639\n",
            "2581\n",
            "2591\n",
            "2917\n",
            "2456\n",
            "365\n",
            "1265\n",
            "5924\n",
            "1083\n",
            "1093\n",
            "784\n",
            "2512\n",
            "1459\n",
            "451\n",
            "1603\n",
            "2858\n",
            "3545\n",
            "1098\n",
            "1517\n",
            "1967\n",
            "691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHhfloPi2yTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfd6814-dc39-4ccf-a9b0-7c76d30ca4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int8)]\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# for song in all_songs:\n",
        "#     print(len(song))\n",
        "print(all_songs)\n",
        "print(all_songs_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n2IaVfy2yTO",
        "outputId": "0e14b227-bf3f-4def-8586-f0d580a25d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(356057, 128)\n",
            "vocab size: 40000\n",
            "vocab first 5 words: ['<UNK>', '', (), (72,), (67,)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-93349b652c35>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  unique_note_intergerized = np.array(mlb.inverse_transform(unique_np))\n"
          ]
        }
      ],
      "source": [
        "print(all_songs_np.shape)\n",
        "unique_np, counts = np.unique(all_songs_np, axis=0, return_counts=True)\n",
        "\n",
        "unique_note_intergerized = np.array(mlb.inverse_transform(unique_np))\n",
        "count_sort_ind = np.argsort(-counts)\n",
        "\n",
        "vocab = unique_note_intergerized[count_sort_ind][:vocab_size-2].tolist()\n",
        "top_counts = counts[count_sort_ind][:vocab_size-1].tolist()\n",
        "# vocab.insert(unk_tag_idx, unk_tag_str)\n",
        "\n",
        "vocab.sort(key=len)\n",
        "# vocab = unique_note_intergerized\n",
        "vocab.insert(unk_tag_idx, unk_tag_str)\n",
        "vocab.insert(pad_tag_idx, pad_tag_str)\n",
        "vocab_size = len(vocab)\n",
        "# vocab_size = 54000\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "print(f\"vocab first 5 words: {vocab[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WNKmQ9N2yTP",
        "outputId": "586b467d-e60b-4eab-f7e5-d6443cc513e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing song number 0\n",
            "processing song number 1\n",
            "processing song number 2\n",
            "processing song number 3\n",
            "processing song number 4\n",
            "processing song number 5\n",
            "processing song number 6\n",
            "processing song number 7\n",
            "processing song number 8\n",
            "processing song number 9\n",
            "processing song number 10\n",
            "processing song number 11\n",
            "processing song number 12\n",
            "processing song number 13\n",
            "processing song number 14\n",
            "processing song number 15\n",
            "processing song number 16\n",
            "processing song number 17\n",
            "processing song number 18\n",
            "processing song number 19\n",
            "processing song number 20\n",
            "processing song number 21\n",
            "processing song number 22\n",
            "processing song number 23\n",
            "processing song number 24\n",
            "processing song number 25\n",
            "processing song number 26\n",
            "processing song number 27\n",
            "processing song number 28\n",
            "processing song number 29\n",
            "processing song number 30\n",
            "processing song number 31\n",
            "processing song number 32\n",
            "processing song number 33\n",
            "processing song number 34\n",
            "processing song number 35\n",
            "processing song number 36\n",
            "processing song number 37\n",
            "processing song number 38\n",
            "processing song number 39\n",
            "processing song number 40\n",
            "processing song number 41\n",
            "processing song number 42\n",
            "processing song number 43\n",
            "processing song number 44\n",
            "processing song number 45\n",
            "processing song number 46\n",
            "processing song number 47\n",
            "processing song number 48\n",
            "processing song number 49\n",
            "processing song number 50\n",
            "processing song number 51\n",
            "processing song number 52\n",
            "processing song number 53\n",
            "processing song number 54\n",
            "processing song number 55\n",
            "processing song number 56\n",
            "processing song number 57\n",
            "processing song number 58\n",
            "processing song number 59\n",
            "processing song number 60\n",
            "processing song number 61\n",
            "processing song number 62\n",
            "processing song number 63\n",
            "processing song number 64\n",
            "processing song number 65\n",
            "processing song number 66\n",
            "processing song number 67\n",
            "processing song number 68\n",
            "processing song number 69\n",
            "processing song number 70\n",
            "processing song number 71\n",
            "processing song number 72\n",
            "processing song number 73\n",
            "processing song number 74\n",
            "processing song number 75\n",
            "processing song number 76\n",
            "processing song number 77\n",
            "processing song number 78\n",
            "processing song number 79\n",
            "processing song number 80\n",
            "processing song number 81\n",
            "processing song number 82\n",
            "processing song number 83\n",
            "processing song number 84\n",
            "processing song number 85\n",
            "processing song number 86\n",
            "processing song number 87\n",
            "processing song number 88\n",
            "processing song number 89\n",
            "processing song number 90\n",
            "processing song number 91\n",
            "processing song number 92\n",
            "processing song number 93\n",
            "processing song number 94\n",
            "processing song number 95\n",
            "processing song number 96\n",
            "processing song number 97\n",
            "processing song number 98\n",
            "processing song number 99\n",
            "processing song number 100\n",
            "processing song number 101\n",
            "processing song number 102\n",
            "processing song number 103\n",
            "processing song number 104\n",
            "processing song number 105\n",
            "processing song number 106\n",
            "processing song number 107\n",
            "processing song number 108\n",
            "processing song number 109\n",
            "processing song number 110\n",
            "processing song number 111\n",
            "processing song number 112\n",
            "processing song number 113\n",
            "processing song number 114\n",
            "processing song number 115\n",
            "processing song number 116\n",
            "processing song number 117\n",
            "processing song number 118\n",
            "processing song number 119\n",
            "processing song number 120\n",
            "processing song number 121\n",
            "processing song number 122\n",
            "processing song number 123\n",
            "processing song number 124\n",
            "processing song number 125\n",
            "processing song number 126\n",
            "processing song number 127\n",
            "processing song number 128\n",
            "processing song number 129\n",
            "processing song number 130\n",
            "processing song number 131\n",
            "processing song number 132\n",
            "processing song number 133\n",
            "processing song number 134\n",
            "processing song number 135\n",
            "processing song number 136\n",
            "processing song number 137\n",
            "processing song number 138\n",
            "processing song number 139\n",
            "processing song number 140\n",
            "processing song number 141\n",
            "processing song number 142\n",
            "processing song number 143\n",
            "processing song number 144\n",
            "processing song number 145\n",
            "processing song number 146\n",
            "processing song number 147\n",
            "processing song number 148\n",
            "processing song number 149\n",
            "processing song number 150\n",
            "processing song number 151\n",
            "processing song number 152\n",
            "processing song number 153\n",
            "processing song number 154\n",
            "processing song number 155\n",
            "processing song number 156\n",
            "processing song number 157\n",
            "processing song number 158\n",
            "processing song number 159\n",
            "processing song number 160\n",
            "processing song number 161\n",
            "processing song number 162\n",
            "processing song number 163\n",
            "processing song number 164\n",
            "processing song number 165\n",
            "processing song number 166\n",
            "processing song number 167\n",
            "processing song number 168\n",
            "processing song number 169\n",
            "processing song number 170\n",
            "processing song number 171\n",
            "processing song number 172\n",
            "processing song number 173\n",
            "processing song number 174\n",
            "processing song number 175\n",
            "processing song number 176\n",
            "processing song number 177\n",
            "processing song number 178\n",
            "processing song number 179\n",
            "processing song number 180\n",
            "processing song number 181\n",
            "processing song number 182\n",
            "processing song number 183\n",
            "processing song number 184\n",
            "processing song number 185\n",
            "processing song number 186\n",
            "Completed tokenising all song\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "combi_to_int = dict((combi, number) for number, combi in enumerate(vocab))\n",
        "int_to_combi = dict((number, combi) for number, combi in enumerate(vocab))\n",
        "\n",
        "all_song_tokenised = []\n",
        "for idx, song in enumerate(all_songs):\n",
        "    print(f\"processing song number {idx}\")\n",
        "    song = mlb.inverse_transform(song)\n",
        "    song = [combi_to_int[tup] if tup in vocab else unk_tag_idx for tup in song]\n",
        "#     song = [combi_to_int[tup] for tup in song]\n",
        "    all_song_tokenised.append(np.array(song))\n",
        "print(f\"Completed tokenising all song\")\n",
        "\n",
        "#delete to free up memory\n",
        "del all_songs\n",
        "del all_songs_np\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, song in enumerate(all_song_tokenised):\n",
        "  print(f'Song number {i} len: {len(song)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scJgrbmqz18h",
        "outputId": "4910f77c-e4d9-47e3-edd6-22ed2d614383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Song number 0 len: 796\n",
            "Song number 1 len: 893\n",
            "Song number 2 len: 1556\n",
            "Song number 3 len: 2550\n",
            "Song number 4 len: 1277\n",
            "Song number 5 len: 1181\n",
            "Song number 6 len: 2840\n",
            "Song number 7 len: 2645\n",
            "Song number 8 len: 1074\n",
            "Song number 9 len: 2375\n",
            "Song number 10 len: 2163\n",
            "Song number 11 len: 1406\n",
            "Song number 12 len: 1157\n",
            "Song number 13 len: 2205\n",
            "Song number 14 len: 1085\n",
            "Song number 15 len: 3706\n",
            "Song number 16 len: 2548\n",
            "Song number 17 len: 904\n",
            "Song number 18 len: 4190\n",
            "Song number 19 len: 677\n",
            "Song number 20 len: 1471\n",
            "Song number 21 len: 1471\n",
            "Song number 22 len: 1248\n",
            "Song number 23 len: 1248\n",
            "Song number 24 len: 2134\n",
            "Song number 25 len: 2134\n",
            "Song number 26 len: 1261\n",
            "Song number 27 len: 2148\n",
            "Song number 28 len: 4435\n",
            "Song number 29 len: 2059\n",
            "Song number 30 len: 1835\n",
            "Song number 31 len: 2354\n",
            "Song number 32 len: 1595\n",
            "Song number 33 len: 1250\n",
            "Song number 34 len: 884\n",
            "Song number 35 len: 1038\n",
            "Song number 36 len: 2444\n",
            "Song number 37 len: 1614\n",
            "Song number 38 len: 1290\n",
            "Song number 39 len: 1902\n",
            "Song number 40 len: 1001\n",
            "Song number 41 len: 1881\n",
            "Song number 42 len: 2690\n",
            "Song number 43 len: 2056\n",
            "Song number 44 len: 706\n",
            "Song number 45 len: 1298\n",
            "Song number 46 len: 1120\n",
            "Song number 47 len: 2307\n",
            "Song number 48 len: 1834\n",
            "Song number 49 len: 2006\n",
            "Song number 50 len: 903\n",
            "Song number 51 len: 2179\n",
            "Song number 52 len: 920\n",
            "Song number 53 len: 1211\n",
            "Song number 54 len: 2088\n",
            "Song number 55 len: 2480\n",
            "Song number 56 len: 1816\n",
            "Song number 57 len: 1139\n",
            "Song number 58 len: 2648\n",
            "Song number 59 len: 2563\n",
            "Song number 60 len: 775\n",
            "Song number 61 len: 1501\n",
            "Song number 62 len: 748\n",
            "Song number 63 len: 653\n",
            "Song number 64 len: 2304\n",
            "Song number 65 len: 1973\n",
            "Song number 66 len: 945\n",
            "Song number 67 len: 2029\n",
            "Song number 68 len: 3657\n",
            "Song number 69 len: 1263\n",
            "Song number 70 len: 1381\n",
            "Song number 71 len: 1640\n",
            "Song number 72 len: 2511\n",
            "Song number 73 len: 2494\n",
            "Song number 74 len: 2494\n",
            "Song number 75 len: 435\n",
            "Song number 76 len: 867\n",
            "Song number 77 len: 1954\n",
            "Song number 78 len: 2692\n",
            "Song number 79 len: 4639\n",
            "Song number 80 len: 2972\n",
            "Song number 81 len: 2972\n",
            "Song number 82 len: 2114\n",
            "Song number 83 len: 5563\n",
            "Song number 84 len: 387\n",
            "Song number 85 len: 2083\n",
            "Song number 86 len: 1619\n",
            "Song number 87 len: 1034\n",
            "Song number 88 len: 326\n",
            "Song number 89 len: 2047\n",
            "Song number 90 len: 2922\n",
            "Song number 91 len: 2580\n",
            "Song number 92 len: 1203\n",
            "Song number 93 len: 1568\n",
            "Song number 94 len: 455\n",
            "Song number 95 len: 1847\n",
            "Song number 96 len: 1409\n",
            "Song number 97 len: 3039\n",
            "Song number 98 len: 2545\n",
            "Song number 99 len: 3178\n",
            "Song number 100 len: 2194\n",
            "Song number 101 len: 993\n",
            "Song number 102 len: 1581\n",
            "Song number 103 len: 1581\n",
            "Song number 104 len: 1137\n",
            "Song number 105 len: 1057\n",
            "Song number 106 len: 2103\n",
            "Song number 107 len: 1284\n",
            "Song number 108 len: 3912\n",
            "Song number 109 len: 3415\n",
            "Song number 110 len: 3416\n",
            "Song number 111 len: 2285\n",
            "Song number 112 len: 1489\n",
            "Song number 113 len: 1300\n",
            "Song number 114 len: 755\n",
            "Song number 115 len: 876\n",
            "Song number 116 len: 4071\n",
            "Song number 117 len: 1953\n",
            "Song number 118 len: 2143\n",
            "Song number 119 len: 2625\n",
            "Song number 120 len: 1802\n",
            "Song number 121 len: 3181\n",
            "Song number 122 len: 1802\n",
            "Song number 123 len: 2451\n",
            "Song number 124 len: 3015\n",
            "Song number 125 len: 2751\n",
            "Song number 126 len: 821\n",
            "Song number 127 len: 1023\n",
            "Song number 128 len: 1838\n",
            "Song number 129 len: 2085\n",
            "Song number 130 len: 709\n",
            "Song number 131 len: 661\n",
            "Song number 132 len: 1501\n",
            "Song number 133 len: 533\n",
            "Song number 134 len: 785\n",
            "Song number 135 len: 1342\n",
            "Song number 136 len: 645\n",
            "Song number 137 len: 2097\n",
            "Song number 138 len: 1676\n",
            "Song number 139 len: 2489\n",
            "Song number 140 len: 2173\n",
            "Song number 141 len: 5266\n",
            "Song number 142 len: 2901\n",
            "Song number 143 len: 618\n",
            "Song number 144 len: 761\n",
            "Song number 145 len: 1681\n",
            "Song number 146 len: 918\n",
            "Song number 147 len: 3251\n",
            "Song number 148 len: 1723\n",
            "Song number 149 len: 1224\n",
            "Song number 150 len: 2249\n",
            "Song number 151 len: 1683\n",
            "Song number 152 len: 1139\n",
            "Song number 153 len: 2137\n",
            "Song number 154 len: 3670\n",
            "Song number 155 len: 3262\n",
            "Song number 156 len: 2672\n",
            "Song number 157 len: 1549\n",
            "Song number 158 len: 2748\n",
            "Song number 159 len: 2467\n",
            "Song number 160 len: 1888\n",
            "Song number 161 len: 1646\n",
            "Song number 162 len: 3148\n",
            "Song number 163 len: 1293\n",
            "Song number 164 len: 1606\n",
            "Song number 165 len: 1901\n",
            "Song number 166 len: 1639\n",
            "Song number 167 len: 2581\n",
            "Song number 168 len: 2591\n",
            "Song number 169 len: 2917\n",
            "Song number 170 len: 2456\n",
            "Song number 171 len: 365\n",
            "Song number 172 len: 1265\n",
            "Song number 173 len: 5924\n",
            "Song number 174 len: 1083\n",
            "Song number 175 len: 1093\n",
            "Song number 176 len: 784\n",
            "Song number 177 len: 2512\n",
            "Song number 178 len: 1459\n",
            "Song number 179 len: 451\n",
            "Song number 180 len: 1603\n",
            "Song number 181 len: 2858\n",
            "Song number 182 len: 3545\n",
            "Song number 183 len: 1098\n",
            "Song number 184 len: 1517\n",
            "Song number 185 len: 1967\n",
            "Song number 186 len: 691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUYTBP1A2yTQ"
      },
      "source": [
        "### Import variables from pickle ( if you did not manually process and tokenise data yourself)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPiOdMRj2yTQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # with open('./16v2/combi_to_int.pickle', 'wb') as f:\n",
        "# #     pickle.dump(combi_to_int, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "# # with open('./16v2/int_to_combi.pickle', 'wb') as f:\n",
        "# #     pickle.dump(int_to_combi, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "# # with open('./16v2/vocab.pickle', 'wb') as f:\n",
        "# #     pickle.dump(vocab, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "# # with open('./16v2/all_song_tokenised.pickle', 'wb') as f:\n",
        "# #     pickle.dump(all_song_tokenised, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# with open('/content/drive/MyDrive/5 - Music Generation by GPT/16v2/combi_to_int.pickle', 'rb') as f:\n",
        "#     combi_to_int = pickle.load(f)\n",
        "    \n",
        "# with open('/content/drive/MyDrive/5 - Music Generation by GPT/16v2/all_song_tokenised.pickle', 'rb') as f:\n",
        "#     all_song_tokenised = pickle.load(f)\n",
        "\n",
        "# with open('/content/drive/MyDrive/5 - Music Generation by GPT/16v2/int_to_combi.pickle', 'rb') as f:\n",
        "#     int_to_combi = pickle.load(f)\n",
        "    \n",
        "# with open('/content/drive/MyDrive/5 - Music Generation by GPT/16v2/vocab.pickle', 'rb') as f:\n",
        "#     vocab = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXXf_pW02yTR",
        "outputId": "3223c478-8a50-47a7-bef6-aff12b4d1680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data:[ 3101  3101  2016  2016  2016  3101  3101  3101  8738  8738  8738  8738\n",
            "  8738  8738 22057   360   360   360  2954  2954  2954  8531  8531  8531\n",
            "  8531 15398 15398 15398 15398 15398 15398 15398 24033 24033 24033 24033\n",
            " 24033 38057 15645 15645 15645 23969 23969 23969 22696 22696 22696 30116\n",
            " 30116 30116 30116 30116 22696 22696 22696 22696 22696 22696 22696 22696\n",
            " 22696 22696 22696 22696 22696 22696 35533  2436  2436  2436  2436  9768\n",
            "  9768  9768  9768  8531  8531  8531 15398 15398 15398 15398 24033   373\n",
            "   373   373  4317  4317  4317 28800  9781  9781 16451 16451 16451 14765\n",
            " 14765 14765 16451 16451 16451 14765 14765 14765 14765 14765 14765 14765\n",
            "  2436  2436  2436  9703  9703  9703  9703 16191 16191 16191 16191 16191\n",
            " 16191 16191 23766 23766 23766 23766 23766 23766 23766     2     6     6\n",
            "     6     6  5004 14918 14918 14918 14918 14918 14918 14918 25075 25075\n",
            " 25075 25075 31530 31530 21083    29     2     2     2    46     2    11\n",
            "  1868     0  1868  7709  7709  1868  1868  1868  7240  7240  7240 15544\n",
            " 15544 15544 25532 25532 25532 30904 30904 30904 34861 34861 36112 36112\n",
            " 36112 36112 37542 37542 37542 38981   199   199   199  1951  1951  1951\n",
            "  1951 22733 22733 22733 22733 22733 22733 22733 22733 22733 22733 22733\n",
            " 22733 22733 22733 22733 22733 22733 22733 20541  9131  9131  9131  9131\n",
            " 33453 33453 33453 33453 33453 33453 33453 33453 33453 38224 38224 38224\n",
            " 38224 38224 38224 38224 39128 39128 39128 39128 39128 39128  1906  1906\n",
            "  1906  1906  1906 18270 18270 18270     0 37759 37759 38854 38854 38854\n",
            " 39412 39412 39531 39531 39531     0  5351 18287 18287 18287 10251 10251\n",
            " 10251 25624 25624 25624 32023 32023 36053 36053 36053 36053  6841    25\n",
            "   547  3019  3019  3019 18280 18280 18280 25547 25547 25547 33554 33554\n",
            " 33554 33554 33554 33554 33554 15951  6990  6990 14375 14375 14375 14375\n",
            " 29642 15111 15111 15111 15111 15111 15111 15111 15111 15111 22899 22899\n",
            " 22899 22899 22899 22899 22899 30164 30164 30164 30164 30164  4842  4842\n",
            "   322  3376 21235 32084 32084 35352 36962 37442 37442 37442 37442 38642\n",
            " 38879 38879 38879 39277 39420 39420 14903 14903 14903  7436 14903 14903\n",
            " 14903 14903 14903 14903 14903 14903 14903 14903 14903 14903 24225 24225\n",
            " 24225 24225 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474\n",
            " 33474 33474 33474     0 14584 14584 14584 14584 14584 14584 14584 14584\n",
            " 14584 22520 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787 14787 14787 14787 14787 14787 23123 23123 23123 23123 23123\n",
            " 23123 23123 23123 23123 23123 23123 30228 30228 30228 30228 30228 34955\n",
            "   262   262   262   262  3101    33 10921    33    33    33   793   793\n",
            " 24045 24045 24045 24045 24045 24045 37085 23405   895   895 22058 29955\n",
            " 29955 22686 22686 22686 22686 22686 22686 22686 22686 22686 22686 22686\n",
            " 22686 22686 35531   128  1953   128  7414  1883  7521   156   625    26\n",
            "  7414  7414  7414  7414 14472 14472 14472 14472 14472 35355    13    13\n",
            "     2     0   367 10767     2    42    42 10767     0    26  1857     2\n",
            "    42    31  1857  1857 14765 14765  7285  7285  7285 18389 18389 18389\n",
            "   187  2083   187  3071  2083   187  9611  8678    22   200     2    10\n",
            "  7240  1868  7765  1868   799    29    29  7435  7435 18536    94    31\n",
            "    31  1797  1797  1797  8127  8127  8127     2    49    49   506   506\n",
            " 30288 30288 30288 30288 30288 34377 34377 34377 35838 35838 35838 35838\n",
            " 35838 35838 35838 35838 37970 10876 10876 18975 18975 26220 26220 37151\n",
            "  7373 19561 19561 26699 26699 32457 19564  7433  7433  7433 26701 26701\n",
            " 21594 13459 19718 19718 25694  1883  1883  1883  1883 28128 21357 18373\n",
            " 18373 22908 22908 22908 22908 22908 22908 22908     0  7564  7564  7564]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sample data:{all_song_tokenised[1][:sequence_length]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyE_rYnJqUjo"
      },
      "source": [
        "## Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZOK3emyh0D0"
      },
      "source": [
        "### Embedding Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17Qdsb5Ih4Vk"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "#         self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.maxlen = maxlen\n",
        "        self.maximum_position_encoding = 10000\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'maxlen': self.maxlen,\n",
        "        })\n",
        "        return config\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "    \n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
        "                              np.arange(d_model)[np.newaxis, :],\n",
        "                              d_model)\n",
        "\n",
        "        # apply sin to even indices in the array; 2i\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # apply cos to odd indices in the array; 2i+1\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "        \n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        pos_encoding = self.positional_encoding(self.maximum_position_encoding, self.embed_dim)\n",
        "        x = self.token_emb(x)\n",
        "        return x + pos_encoding[:,:maxlen,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43gMQ-pg2yTS"
      },
      "outputs": [],
      "source": [
        "# maxlen=5\n",
        "# vocab_size=12\n",
        "# embed_dim = 3\n",
        "# b= np.zeros((3,5))\n",
        "# bb = tf.convert_to_tensor(b, dtype=float)\n",
        "\n",
        "# # inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "# embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "# # x = embedding_layer(inputs)\n",
        "# x = embedding_layer(bb)\n",
        "# print(x )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh3RhUvE8cKt"
      },
      "source": [
        "### Self-attention with causal masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfaLa27o9AgN"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        #defining no of nodes/dim for each layer\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @staticmethod\n",
        "    def causal_attention_mask(n_dest, n_src, dtype):\n",
        "        \"\"\"\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        return tf.cast(m, dtype)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "\n",
        "        # prevent information flow from future tokens\n",
        "        shape = tf.shape(scaled_score)\n",
        "        dim_dest, dim_src = shape[2], shape[3]\n",
        "        attention_mask = self.causal_attention_mask(\n",
        "            dim_dest, dim_src, scaled_score.dtype\n",
        "        )\n",
        "        attention_mask = tf.reshape(attention_mask, [1, 1, dim_dest, dim_src])\n",
        "        scaled_score = scaled_score * attention_mask - 1e4 * (1 - attention_mask)\n",
        "\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXWdP8DgnUK"
      },
      "source": [
        "### Transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDvR-OPdgqbu"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "            'ff_dim': self.ff_dim,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_output = self.att(inputs)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wH-kaFSjC7G"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I0tMJJBjGNd"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "def create_model():\n",
        "    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block1 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block2 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block3 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    x = transformer_block1(x)\n",
        "    x = transformer_block2(x)\n",
        "    x = transformer_block3(x)\n",
        "    outputs = layers.Dense(vocab_size)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "        \"adam\", loss=[loss_fn, None],\n",
        "    )  # No loss and optimization based on word embeddings from transformer block\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGV_W2432yTV",
        "outputId": "ea498235-44f1-48d3-8cec-104b00965174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcQFTj9s2yTV",
        "outputId": "7d90fa99-7956-4485-a64f-961d8539c9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 600, 128)         5120000   \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_block (Transfor  (None, 600, 128)         99584     \n",
            " merBlock)                                                       \n",
            "                                                                 \n",
            " transformer_block_1 (Transf  (None, 600, 128)         99584     \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " transformer_block_2 (Transf  (None, 600, 128)         99584     \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 600, 40000)        5160000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,578,752\n",
            "Trainable params: 10,578,752\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xANyYPyz2yTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebe08cd-b7ae-44e3-ecba-2f3c4ee4790c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, multi_head_self_attention_layer_call_fn, multi_head_self_attention_layer_call_and_return_conditional_losses while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# model.save('/content/drive/MyDrive/5 - Music Generation by GPT/MuGenTransformer-v3-data16v2-stable')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPCfkqsx2yTW"
      },
      "source": [
        "## Generator\n",
        "Custom generator to input one random sequence from each song to train. (Instead of the old method of one shot loading all iterative sequence to the model to train, referenced from MusicTransformer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtuA2auk2yTW"
      },
      "outputs": [],
      "source": [
        "class My_Custom_Generator(keras.utils.Sequence) :\n",
        "    def __init__(self, all_song_tokenised, batch_size, sequence_length, val_split = 0, shuffle=True) :\n",
        "        self.all_song_tokenised = all_song_tokenised\n",
        "        self.pad_tag_idx = 1\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.val_split = val_split\n",
        "        if(self.val_split != 0):\n",
        "            self.all_song_tokenised = random.choices(self.all_song_tokenised, k = int(self.val_split*len(self.all_song_tokenised)))\n",
        "            self.batch_size = len(self.all_song_tokenised)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self) :\n",
        "#         return (np.ceil((len(self.pickle_filenames)* self.data_per_file)/ float(self.batch_size))).astype(np.int)\n",
        "        return int(np.ceil(len(self.all_song_tokenised)/ self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.all_song_tokenised)\n",
        "  \n",
        "    def __getitem__(self, idx) :\n",
        "        batch_x = np.empty((0, self.sequence_length), float)\n",
        "        batch_y = np.empty((0, self.sequence_length), float)\n",
        "        for i in range(self.batch_size):\n",
        "            if(idx*self.batch_size + i == len(self.all_song_tokenised)-1):\n",
        "                return batch_x, batch_y\n",
        "            song = self.all_song_tokenised[idx*self.batch_size + i]\n",
        "            start_idx = random.randint(0,len(song) - self.sequence_length/2)\n",
        "            seq = song[start_idx: start_idx + self.sequence_length + 1]\n",
        "            x= seq[:-1]\n",
        "            y = seq[1:]\n",
        "#           padding if needed\n",
        "            if(len(y) < self.sequence_length):\n",
        "                no_of_pad = self.sequence_length - len(y)\n",
        "                x = np.append(x, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "                y = np.append(y, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "#             print(idx*batch_size + i)\n",
        "#             while (np.unique(seq).shape[0] == 1):\n",
        "#                 start_idx = random.randint(0,len(song) - self.sequence_length-2)\n",
        "#                 seq = song[start_idx: start_idx + self.sequence_length + 1]\n",
        "            \n",
        "            batch_x = np.append(batch_x, [x], axis = 0)\n",
        "            batch_y = np.append(batch_y, [y], axis = 0)\n",
        "            \n",
        "        return batch_x, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl_wPnUF2yTX"
      },
      "source": [
        "## Sequence Generator callback:\n",
        "To show an instance of how the model behave once every specified epochs. Fixed seed sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boEo1_8H2yTX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GeneratorCallback(keras.callbacks.Callback):\n",
        "    \"\"\"Callback to generate text from trained model.\n",
        "    1. Feed some starting prompt to the model\n",
        "    2. Predict probabilities for next token\n",
        "    3. Sample next token and add it to the next input\n",
        "\n",
        "    # Arguments\n",
        "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
        "        start_tokens: List of integers, the token indices for the starting prompt.\n",
        "        index_to_word: List of strings, obtained from TextVectorization layer.\n",
        "        top_k: Integer, sample from the `top_k` token predictions.\n",
        "        print_every: Integer, print after this many epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, max_tokens, start_tokens, top_k=10, print_every=5\n",
        "    ):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "#         self.index_to_word = index_to_word\n",
        "        self.print_every = print_every\n",
        "        self.k = top_k\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype(\"int32\")\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype(\"float32\")\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        if (epoch + 1) % self.print_every != 0:\n",
        "            return\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            x = start_tokens[-sequence_length:]\n",
        "            pad_len = maxlen - len(start_tokens)\n",
        "            sample_index = -1\n",
        "            if pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "                sample_index = len(start_tokens) - 1\n",
        "            \n",
        "            x = np.array([x])\n",
        "            y, _ = self.model.predict(x)\n",
        "            sample_token = self.sample_from(y[0][sample_index])\n",
        "            tokens_generated.append(sample_token)\n",
        "            start_tokens.append(sample_token)\n",
        "            num_tokens_generated = len(tokens_generated)\n",
        "            \n",
        "#         txt = \" \".join(\n",
        "#             [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
        "#         )\n",
        "\n",
        "        print(f\"last 40 tokens of starting token:\\n{self.start_tokens[-50:]}\\n\")\n",
        "        print(f\"generated token:\\n{tokens_generated}\\n\")\n",
        "\n",
        "start_tokens = all_song_tokenised[1][:sequence_length-200]\n",
        "num_tokens_generated = 80\n",
        "gen_callback = GeneratorCallback(num_tokens_generated, start_tokens, print_every= generate_sample_every_ep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cakuQDUb2yTX"
      },
      "source": [
        "## Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdYX2uH32yTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2e840fa-6956-4a65-bd31-6ed0f921414a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 21s 862ms/step - loss: 10.4080 - dense_18_loss: 10.4080 - val_loss: 10.1293 - val_dense_18_loss: 10.1293\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 4s 715ms/step - loss: 9.8884 - dense_18_loss: 9.8884 - val_loss: 9.5556 - val_dense_18_loss: 9.5556\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 3s 593ms/step - loss: 9.4544 - dense_18_loss: 9.4544 - val_loss: 9.2103 - val_dense_18_loss: 9.2103\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 3s 581ms/step - loss: 9.0951 - dense_18_loss: 9.0951 - val_loss: 8.9071 - val_dense_18_loss: 8.9071\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 4s 666ms/step - loss: 8.7132 - dense_18_loss: 8.7132 - val_loss: 8.8702 - val_dense_18_loss: 8.8702\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 8.6170 - dense_18_loss: 8.6170 - val_loss: 8.5144 - val_dense_18_loss: 8.5144\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 3s 580ms/step - loss: 8.3537 - dense_18_loss: 8.3537 - val_loss: 7.9632 - val_dense_18_loss: 7.9632\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 3s 584ms/step - loss: 8.1928 - dense_18_loss: 8.1928 - val_loss: 8.2733 - val_dense_18_loss: 8.2733\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 4s 702ms/step - loss: 8.0759 - dense_18_loss: 8.0759 - val_loss: 8.4419 - val_dense_18_loss: 8.4419\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 3s 586ms/step - loss: 8.0675 - dense_18_loss: 8.0675 - val_loss: 8.2929 - val_dense_18_loss: 8.2929\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 7.9947 - dense_18_loss: 7.9947 - val_loss: 7.9414 - val_dense_18_loss: 7.9414\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 8.0621 - dense_18_loss: 8.0621 - val_loss: 8.1760 - val_dense_18_loss: 8.1760\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 3s 590ms/step - loss: 7.9628 - dense_18_loss: 7.9628 - val_loss: 7.8934 - val_dense_18_loss: 7.8934\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 4s 624ms/step - loss: 7.8438 - dense_18_loss: 7.8438 - val_loss: 8.3214 - val_dense_18_loss: 8.3214\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 7.9777 - dense_18_loss: 7.9777 - val_loss: 8.2904 - val_dense_18_loss: 8.2904\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 7.9629 - dense_18_loss: 7.9629 - val_loss: 8.2787 - val_dense_18_loss: 8.2787\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 7.8487 - dense_18_loss: 7.8487 - val_loss: 7.9570 - val_dense_18_loss: 7.9570\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 4s 747ms/step - loss: 7.8412 - dense_18_loss: 7.8412 - val_loss: 8.3060 - val_dense_18_loss: 8.3060\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 4s 710ms/step - loss: 7.8343 - dense_18_loss: 7.8343 - val_loss: 7.9593 - val_dense_18_loss: 7.9593\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 7.7491 - dense_18_loss: 7.7491 - val_loss: 8.0022 - val_dense_18_loss: 8.0022\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 3s 490ms/step - loss: 7.8533 - dense_18_loss: 7.8533 - val_loss: 7.9233 - val_dense_18_loss: 7.9233\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 3s 604ms/step - loss: 7.6192 - dense_18_loss: 7.6192 - val_loss: 8.1169 - val_dense_18_loss: 8.1169\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 4s 588ms/step - loss: 7.6861 - dense_18_loss: 7.6861 - val_loss: 7.6969 - val_dense_18_loss: 7.6969\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 7.7507 - dense_18_loss: 7.7507 - val_loss: 7.8250 - val_dense_18_loss: 7.8250\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 3s 491ms/step - loss: 7.6354 - dense_18_loss: 7.6354 - val_loss: 7.6204 - val_dense_18_loss: 7.6204\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 5s 869ms/step - loss: 7.5188 - dense_18_loss: 7.5188 - val_loss: 7.7307 - val_dense_18_loss: 7.7307\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 3s 504ms/step - loss: 7.6086 - dense_18_loss: 7.6086 - val_loss: 7.8155 - val_dense_18_loss: 7.8155\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 3s 503ms/step - loss: 7.6070 - dense_18_loss: 7.6070 - val_loss: 7.8515 - val_dense_18_loss: 7.8515\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 3s 603ms/step - loss: 7.3787 - dense_18_loss: 7.3787 - val_loss: 7.8617 - val_dense_18_loss: 7.8617\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 4s 598ms/step - loss: 7.4699 - dense_18_loss: 7.4699 - val_loss: 7.4641 - val_dense_18_loss: 7.4641\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 3s 500ms/step - loss: 7.5087 - dense_18_loss: 7.5087 - val_loss: 7.4652 - val_dense_18_loss: 7.4652\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 3s 500ms/step - loss: 7.5704 - dense_18_loss: 7.5704 - val_loss: 7.6127 - val_dense_18_loss: 7.6127\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 7.4935 - dense_18_loss: 7.4935 - val_loss: 7.7687 - val_dense_18_loss: 7.7687\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 5s 844ms/step - loss: 7.1627 - dense_18_loss: 7.1627 - val_loss: 7.2743 - val_dense_18_loss: 7.2743\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 3s 499ms/step - loss: 7.3821 - dense_18_loss: 7.3821 - val_loss: 7.3902 - val_dense_18_loss: 7.3902\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 3s 505ms/step - loss: 7.3638 - dense_18_loss: 7.3638 - val_loss: 7.6373 - val_dense_18_loss: 7.6373\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 7.3233 - dense_18_loss: 7.3233 - val_loss: 7.7491 - val_dense_18_loss: 7.7491\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 7.3758 - dense_18_loss: 7.3758 - val_loss: 6.8829 - val_dense_18_loss: 6.8829\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 3s 509ms/step - loss: 7.2042 - dense_18_loss: 7.2042 - val_loss: 7.5605 - val_dense_18_loss: 7.5605\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 7.2655 - dense_18_loss: 7.2655 - val_loss: 7.2938 - val_dense_18_loss: 7.2938\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 4s 608ms/step - loss: 7.2290 - dense_18_loss: 7.2290 - val_loss: 7.0066 - val_dense_18_loss: 7.0066\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 4s 764ms/step - loss: 7.1393 - dense_18_loss: 7.1393 - val_loss: 7.4164 - val_dense_18_loss: 7.4164\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 7.0370 - dense_18_loss: 7.0370 - val_loss: 7.7198 - val_dense_18_loss: 7.7198\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 7.0998 - dense_18_loss: 7.0998 - val_loss: 7.5880 - val_dense_18_loss: 7.5880\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 5s 797ms/step - loss: 6.9823 - dense_18_loss: 6.9823 - val_loss: 7.7223 - val_dense_18_loss: 7.7223\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 7.0299 - dense_18_loss: 7.0299 - val_loss: 7.2726 - val_dense_18_loss: 7.2726\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 4s 701ms/step - loss: 6.9665 - dense_18_loss: 6.9665 - val_loss: 7.3358 - val_dense_18_loss: 7.3358\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 6.9851 - dense_18_loss: 6.9851 - val_loss: 6.7889 - val_dense_18_loss: 6.7889\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 4s 619ms/step - loss: 6.8774 - dense_18_loss: 6.8774 - val_loss: 7.3172 - val_dense_18_loss: 7.3172\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 6.9880 - dense_18_loss: 6.9880 - val_loss: 7.2537 - val_dense_18_loss: 7.2537\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 4s 602ms/step - loss: 6.9471 - dense_18_loss: 6.9471 - val_loss: 7.3945 - val_dense_18_loss: 7.3945\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 4s 754ms/step - loss: 6.7574 - dense_18_loss: 6.7574 - val_loss: 6.7060 - val_dense_18_loss: 6.7060\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 7.0206 - dense_18_loss: 7.0206 - val_loss: 6.9094 - val_dense_18_loss: 6.9094\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 4s 613ms/step - loss: 6.9715 - dense_18_loss: 6.9715 - val_loss: 7.3710 - val_dense_18_loss: 7.3710\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 6.7517 - dense_18_loss: 6.7517 - val_loss: 6.9425 - val_dense_18_loss: 6.9425\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 6.7577 - dense_18_loss: 6.7577 - val_loss: 7.0519 - val_dense_18_loss: 7.0519\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 4s 746ms/step - loss: 6.7445 - dense_18_loss: 6.7445 - val_loss: 7.2558 - val_dense_18_loss: 7.2558\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 6.8620 - dense_18_loss: 6.8620 - val_loss: 7.0372 - val_dense_18_loss: 7.0372\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 4s 703ms/step - loss: 6.7392 - dense_18_loss: 6.7392 - val_loss: 7.0080 - val_dense_18_loss: 7.0080\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 4s 722ms/step - loss: 6.7260 - dense_18_loss: 6.7260 - val_loss: 6.8020 - val_dense_18_loss: 6.8020\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 6.8082 - dense_18_loss: 6.8082 - val_loss: 6.9830 - val_dense_18_loss: 6.9830\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 6.6938 - dense_18_loss: 6.6938 - val_loss: 6.7316 - val_dense_18_loss: 6.7316\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 6.6831 - dense_18_loss: 6.6831 - val_loss: 6.7988 - val_dense_18_loss: 6.7988\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 4s 685ms/step - loss: 6.6795 - dense_18_loss: 6.6795 - val_loss: 6.8652 - val_dense_18_loss: 6.8652\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 4s 620ms/step - loss: 6.5706 - dense_18_loss: 6.5706 - val_loss: 7.1839 - val_dense_18_loss: 7.1839\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 6.6985 - dense_18_loss: 6.6985 - val_loss: 7.2420 - val_dense_18_loss: 7.2420\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 4s 617ms/step - loss: 6.6992 - dense_18_loss: 6.6992 - val_loss: 6.3850 - val_dense_18_loss: 6.3850\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 4s 746ms/step - loss: 6.4985 - dense_18_loss: 6.4985 - val_loss: 6.4290 - val_dense_18_loss: 6.4290\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 6.5070 - dense_18_loss: 6.5070 - val_loss: 6.5508 - val_dense_18_loss: 6.5508\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 4s 728ms/step - loss: 6.3871 - dense_18_loss: 6.3871 - val_loss: 6.5164 - val_dense_18_loss: 6.5164\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 3s 510ms/step - loss: 6.5123 - dense_18_loss: 6.5123 - val_loss: 6.5357 - val_dense_18_loss: 6.5357\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 6.5995 - dense_18_loss: 6.5995 - val_loss: 6.8573 - val_dense_18_loss: 6.8573\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 4s 605ms/step - loss: 6.4173 - dense_18_loss: 6.4173 - val_loss: 6.7821 - val_dense_18_loss: 6.7821\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 6.5237 - dense_18_loss: 6.5237 - val_loss: 6.9667 - val_dense_18_loss: 6.9667\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 4s 772ms/step - loss: 6.2742 - dense_18_loss: 6.2742 - val_loss: 7.0872 - val_dense_18_loss: 7.0872\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 6.4973 - dense_18_loss: 6.4973 - val_loss: 6.6303 - val_dense_18_loss: 6.6303\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 6.4656 - dense_18_loss: 6.4656 - val_loss: 6.7185 - val_dense_18_loss: 6.7185\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 6.2572 - dense_18_loss: 6.2572 - val_loss: 6.2761 - val_dense_18_loss: 6.2761\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 6.3448 - dense_18_loss: 6.3448 - val_loss: 6.2257 - val_dense_18_loss: 6.2257\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 4s 691ms/step - loss: 6.2379 - dense_18_loss: 6.2379 - val_loss: 6.1452 - val_dense_18_loss: 6.1452\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 4s 604ms/step - loss: 6.1973 - dense_18_loss: 6.1973 - val_loss: 6.7271 - val_dense_18_loss: 6.7271\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 6.2128 - dense_18_loss: 6.2128 - val_loss: 6.1732 - val_dense_18_loss: 6.1732\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 6.2704 - dense_18_loss: 6.2704 - val_loss: 6.4763 - val_dense_18_loss: 6.4763\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 3s 557ms/step - loss: 6.2076 - dense_18_loss: 6.2076 - val_loss: 5.5824 - val_dense_18_loss: 5.5824\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 4s 778ms/step - loss: 5.9962 - dense_18_loss: 5.9962 - val_loss: 6.0803 - val_dense_18_loss: 6.0803\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 3s 601ms/step - loss: 6.0317 - dense_18_loss: 6.0317 - val_loss: 5.9638 - val_dense_18_loss: 5.9638\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 6.0620 - dense_18_loss: 6.0620 - val_loss: 5.9422 - val_dense_18_loss: 5.9422\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 6.1365 - dense_18_loss: 6.1365 - val_loss: 6.1343 - val_dense_18_loss: 6.1343\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 4s 766ms/step - loss: 5.9591 - dense_18_loss: 5.9591 - val_loss: 5.9641 - val_dense_18_loss: 5.9641\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 6.1537 - dense_18_loss: 6.1537 - val_loss: 6.2259 - val_dense_18_loss: 6.2259\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 4s 692ms/step - loss: 5.9373 - dense_18_loss: 5.9373 - val_loss: 6.2841 - val_dense_18_loss: 6.2841\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 5.9937 - dense_18_loss: 5.9937 - val_loss: 6.5482 - val_dense_18_loss: 6.5482\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 5.9427 - dense_18_loss: 5.9427 - val_loss: 6.1790 - val_dense_18_loss: 6.1790\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 5s 824ms/step - loss: 5.9092 - dense_18_loss: 5.9092 - val_loss: 6.0418 - val_dense_18_loss: 6.0418\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 5.9892 - dense_18_loss: 5.9892 - val_loss: 6.1815 - val_dense_18_loss: 6.1815\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 6.0004 - dense_18_loss: 6.0004 - val_loss: 5.8956 - val_dense_18_loss: 5.8956\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 5.7665 - dense_18_loss: 5.7665 - val_loss: 6.1947 - val_dense_18_loss: 6.1947\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 5.7850 - dense_18_loss: 5.7850 - val_loss: 5.9217 - val_dense_18_loss: 5.9217\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 5.8079 - dense_18_loss: 5.8079 - val_loss: 6.1484 - val_dense_18_loss: 6.1484\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "last 40 tokens of starting token:\n",
            "[14903 14903 14903 14903 14903 14903 14903 14903 24225 24225 24225 24225\n",
            " 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474 33474 33474\n",
            " 33474     0 14584 14584 14584 14584 14584 14584 14584 14584 14584 22520\n",
            " 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787]\n",
            "\n",
            "generated token:\n",
            "[14903, 14787, 66, 14787, 23123, 23123, 33271, 29247, 29247, 29247, 29250, 29250, 14787, 14787, 644, 22686, 23123, 29250, 14787, 22587, 33271, 33341, 23123, 22686, 29118, 644, 23123, 29118, 33271, 29118, 29250, 644, 14787, 14787, 14787, 14903, 15957, 35879, 15957, 22686, 29118, 24045, 15084, 29118, 23123, 14787, 29250, 33341, 644, 33271, 29118, 15084, 29250, 15124, 29118, 29118, 29250, 644, 14787, 15124, 14787, 33271, 23123, 29118, 33341, 15084, 23046, 3149, 29118, 29118, 29118, 15124, 33271, 29250, 15124, 23123, 2165, 644, 2165, 38193, 33287]\n",
            "\n",
            "6/6 [==============================] - 20s 4s/step - loss: 5.7848 - dense_18_loss: 5.7848 - val_loss: 5.7658 - val_dense_18_loss: 5.7658\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 5s 845ms/step - loss: 5.6700 - dense_18_loss: 5.6700 - val_loss: 6.0631 - val_dense_18_loss: 6.0631\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 5.5716 - dense_18_loss: 5.5716 - val_loss: 6.0550 - val_dense_18_loss: 6.0550\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 5.7385 - dense_18_loss: 5.7385 - val_loss: 5.6998 - val_dense_18_loss: 5.6998\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 3s 574ms/step - loss: 5.6552 - dense_18_loss: 5.6552 - val_loss: 5.9507 - val_dense_18_loss: 5.9507\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 5.6668 - dense_18_loss: 5.6668 - val_loss: 5.8302 - val_dense_18_loss: 5.8302\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 5.7946 - dense_18_loss: 5.7946 - val_loss: 5.6381 - val_dense_18_loss: 5.6381\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 5s 825ms/step - loss: 5.5640 - dense_18_loss: 5.5640 - val_loss: 5.1947 - val_dense_18_loss: 5.1947\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 5.6176 - dense_18_loss: 5.6176 - val_loss: 5.5604 - val_dense_18_loss: 5.5604\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 4s 630ms/step - loss: 5.4213 - dense_18_loss: 5.4213 - val_loss: 5.4318 - val_dense_18_loss: 5.4318\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 5.6607 - dense_18_loss: 5.6607 - val_loss: 5.5731 - val_dense_18_loss: 5.5731\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 4s 708ms/step - loss: 5.3634 - dense_18_loss: 5.3634 - val_loss: 5.2013 - val_dense_18_loss: 5.2013\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 5.3680 - dense_18_loss: 5.3680 - val_loss: 5.6907 - val_dense_18_loss: 5.6907\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 4s 626ms/step - loss: 5.2987 - dense_18_loss: 5.2987 - val_loss: 5.7232 - val_dense_18_loss: 5.7232\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 5.4722 - dense_18_loss: 5.4722 - val_loss: 5.5052 - val_dense_18_loss: 5.5052\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 5.4291 - dense_18_loss: 5.4291 - val_loss: 5.5897 - val_dense_18_loss: 5.5897\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 4s 608ms/step - loss: 5.2632 - dense_18_loss: 5.2632 - val_loss: 5.0740 - val_dense_18_loss: 5.0740\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 5.3461 - dense_18_loss: 5.3461 - val_loss: 5.1065 - val_dense_18_loss: 5.1065\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 5.3224 - dense_18_loss: 5.3224 - val_loss: 5.3221 - val_dense_18_loss: 5.3221\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 5.3314 - dense_18_loss: 5.3314 - val_loss: 5.2627 - val_dense_18_loss: 5.2627\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 4s 784ms/step - loss: 5.2400 - dense_18_loss: 5.2400 - val_loss: 4.9211 - val_dense_18_loss: 4.9211\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 4s 690ms/step - loss: 5.1810 - dense_18_loss: 5.1810 - val_loss: 5.0692 - val_dense_18_loss: 5.0692\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 5.1914 - dense_18_loss: 5.1914 - val_loss: 5.3690 - val_dense_18_loss: 5.3690\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 5.2059 - dense_18_loss: 5.2059 - val_loss: 5.2023 - val_dense_18_loss: 5.2023\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 5.2523 - dense_18_loss: 5.2523 - val_loss: 5.0071 - val_dense_18_loss: 5.0071\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 4s 776ms/step - loss: 5.1393 - dense_18_loss: 5.1393 - val_loss: 5.2851 - val_dense_18_loss: 5.2851\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 4s 617ms/step - loss: 5.1089 - dense_18_loss: 5.1089 - val_loss: 5.2263 - val_dense_18_loss: 5.2263\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 4.9744 - dense_18_loss: 4.9744 - val_loss: 5.0551 - val_dense_18_loss: 5.0551\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 5.0641 - dense_18_loss: 5.0641 - val_loss: 5.0013 - val_dense_18_loss: 5.0013\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 5.1750 - dense_18_loss: 5.1750 - val_loss: 5.1863 - val_dense_18_loss: 5.1863\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 5.0479 - dense_18_loss: 5.0479 - val_loss: 4.4969 - val_dense_18_loss: 4.4969\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 5s 789ms/step - loss: 4.9463 - dense_18_loss: 4.9463 - val_loss: 5.0217 - val_dense_18_loss: 5.0217\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 4.9129 - dense_18_loss: 4.9129 - val_loss: 4.5530 - val_dense_18_loss: 4.5530\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 4.9880 - dense_18_loss: 4.9880 - val_loss: 5.0182 - val_dense_18_loss: 5.0182\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 5s 922ms/step - loss: 4.7580 - dense_18_loss: 4.7580 - val_loss: 4.7477 - val_dense_18_loss: 4.7477\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 4.8557 - dense_18_loss: 4.8557 - val_loss: 4.8085 - val_dense_18_loss: 4.8085\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 4.8101 - dense_18_loss: 4.8101 - val_loss: 4.3919 - val_dense_18_loss: 4.3919\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 3s 592ms/step - loss: 4.8800 - dense_18_loss: 4.8800 - val_loss: 4.6111 - val_dense_18_loss: 4.6111\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 5s 790ms/step - loss: 4.7087 - dense_18_loss: 4.7087 - val_loss: 5.0555 - val_dense_18_loss: 5.0555\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 4.8421 - dense_18_loss: 4.8421 - val_loss: 4.5330 - val_dense_18_loss: 4.5330\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 3s 564ms/step - loss: 4.7485 - dense_18_loss: 4.7485 - val_loss: 4.7768 - val_dense_18_loss: 4.7768\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 4.7115 - dense_18_loss: 4.7115 - val_loss: 4.3905 - val_dense_18_loss: 4.3905\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 4s 752ms/step - loss: 4.6596 - dense_18_loss: 4.6596 - val_loss: 4.7112 - val_dense_18_loss: 4.7112\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 3s 560ms/step - loss: 4.6841 - dense_18_loss: 4.6841 - val_loss: 4.4679 - val_dense_18_loss: 4.4679\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 3s 567ms/step - loss: 4.6745 - dense_18_loss: 4.6745 - val_loss: 4.3624 - val_dense_18_loss: 4.3624\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 5s 811ms/step - loss: 4.5379 - dense_18_loss: 4.5379 - val_loss: 4.3477 - val_dense_18_loss: 4.3477\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 4.5696 - dense_18_loss: 4.5696 - val_loss: 4.3184 - val_dense_18_loss: 4.3184\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 4.5459 - dense_18_loss: 4.5459 - val_loss: 4.3864 - val_dense_18_loss: 4.3864\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 4s 628ms/step - loss: 4.5100 - dense_18_loss: 4.5100 - val_loss: 4.4395 - val_dense_18_loss: 4.4395\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 4s 638ms/step - loss: 4.4560 - dense_18_loss: 4.4560 - val_loss: 4.5316 - val_dense_18_loss: 4.5316\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 3s 510ms/step - loss: 4.5330 - dense_18_loss: 4.5330 - val_loss: 4.3417 - val_dense_18_loss: 4.3417\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 4.5093 - dense_18_loss: 4.5093 - val_loss: 4.3356 - val_dense_18_loss: 4.3356\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 4s 750ms/step - loss: 4.4009 - dense_18_loss: 4.4009 - val_loss: 4.4448 - val_dense_18_loss: 4.4448\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 4s 618ms/step - loss: 4.2933 - dense_18_loss: 4.2933 - val_loss: 4.5533 - val_dense_18_loss: 4.5533\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 4s 601ms/step - loss: 4.3747 - dense_18_loss: 4.3747 - val_loss: 4.0399 - val_dense_18_loss: 4.0399\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 4.2587 - dense_18_loss: 4.2587 - val_loss: 3.6994 - val_dense_18_loss: 3.6994\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 4.3803 - dense_18_loss: 4.3803 - val_loss: 3.8883 - val_dense_18_loss: 3.8883\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 4.3281 - dense_18_loss: 4.3281 - val_loss: 3.8543 - val_dense_18_loss: 3.8543\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 4.2612 - dense_18_loss: 4.2612 - val_loss: 4.2023 - val_dense_18_loss: 4.2023\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 4.2934 - dense_18_loss: 4.2934 - val_loss: 3.9832 - val_dense_18_loss: 3.9832\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 4.2858 - dense_18_loss: 4.2858 - val_loss: 4.1859 - val_dense_18_loss: 4.1859\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 5s 819ms/step - loss: 4.1782 - dense_18_loss: 4.1782 - val_loss: 4.1552 - val_dense_18_loss: 4.1552\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 4.2218 - dense_18_loss: 4.2218 - val_loss: 4.1104 - val_dense_18_loss: 4.1104\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 4s 616ms/step - loss: 4.0623 - dense_18_loss: 4.0623 - val_loss: 4.3046 - val_dense_18_loss: 4.3046\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 3s 567ms/step - loss: 4.1100 - dense_18_loss: 4.1100 - val_loss: 3.6774 - val_dense_18_loss: 3.6774\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 4s 621ms/step - loss: 4.0049 - dense_18_loss: 4.0049 - val_loss: 3.5873 - val_dense_18_loss: 3.5873\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 4s 616ms/step - loss: 3.9907 - dense_18_loss: 3.9907 - val_loss: 3.5835 - val_dense_18_loss: 3.5835\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 4.0461 - dense_18_loss: 4.0461 - val_loss: 3.7138 - val_dense_18_loss: 3.7138\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 4s 678ms/step - loss: 3.9737 - dense_18_loss: 3.9737 - val_loss: 3.8853 - val_dense_18_loss: 3.8853\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 4s 615ms/step - loss: 3.8974 - dense_18_loss: 3.8974 - val_loss: 3.4875 - val_dense_18_loss: 3.4875\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 3.9810 - dense_18_loss: 3.9810 - val_loss: 3.5263 - val_dense_18_loss: 3.5263\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 3.9150 - dense_18_loss: 3.9150 - val_loss: 3.6227 - val_dense_18_loss: 3.6227\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 3.9304 - dense_18_loss: 3.9304 - val_loss: 3.8590 - val_dense_18_loss: 3.8590\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 4s 753ms/step - loss: 3.8753 - dense_18_loss: 3.8753 - val_loss: 3.8086 - val_dense_18_loss: 3.8086\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 3s 554ms/step - loss: 3.9199 - dense_18_loss: 3.9199 - val_loss: 3.9002 - val_dense_18_loss: 3.9002\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 3.8603 - dense_18_loss: 3.8603 - val_loss: 3.5657 - val_dense_18_loss: 3.5657\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 3.8153 - dense_18_loss: 3.8153 - val_loss: 3.4509 - val_dense_18_loss: 3.4509\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 4s 638ms/step - loss: 3.7140 - dense_18_loss: 3.7140 - val_loss: 3.3517 - val_dense_18_loss: 3.3517\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 3s 593ms/step - loss: 3.7565 - dense_18_loss: 3.7565 - val_loss: 3.4651 - val_dense_18_loss: 3.4651\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 4s 622ms/step - loss: 3.6737 - dense_18_loss: 3.6737 - val_loss: 3.3761 - val_dense_18_loss: 3.3761\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 3s 554ms/step - loss: 3.7449 - dense_18_loss: 3.7449 - val_loss: 3.3898 - val_dense_18_loss: 3.3898\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 3.6261 - dense_18_loss: 3.6261 - val_loss: 3.7120 - val_dense_18_loss: 3.7120\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 4s 636ms/step - loss: 3.5956 - dense_18_loss: 3.5956 - val_loss: 3.2756 - val_dense_18_loss: 3.2756\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 3.7247 - dense_18_loss: 3.7247 - val_loss: 3.0817 - val_dense_18_loss: 3.0817\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 3.6172 - dense_18_loss: 3.6172 - val_loss: 3.1273 - val_dense_18_loss: 3.1273\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 3.6299 - dense_18_loss: 3.6299 - val_loss: 3.1386 - val_dense_18_loss: 3.1386\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 4s 753ms/step - loss: 3.5405 - dense_18_loss: 3.5405 - val_loss: 3.4919 - val_dense_18_loss: 3.4919\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 3s 555ms/step - loss: 3.6776 - dense_18_loss: 3.6776 - val_loss: 3.1057 - val_dense_18_loss: 3.1057\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 4s 625ms/step - loss: 3.5360 - dense_18_loss: 3.5360 - val_loss: 3.1800 - val_dense_18_loss: 3.1800\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 3.5892 - dense_18_loss: 3.5892 - val_loss: 3.4226 - val_dense_18_loss: 3.4226\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 4s 617ms/step - loss: 3.4545 - dense_18_loss: 3.4545 - val_loss: 3.0365 - val_dense_18_loss: 3.0365\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 4s 674ms/step - loss: 3.4074 - dense_18_loss: 3.4074 - val_loss: 3.0151 - val_dense_18_loss: 3.0151\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 4s 619ms/step - loss: 3.3922 - dense_18_loss: 3.3922 - val_loss: 3.2143 - val_dense_18_loss: 3.2143\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 3.4402 - dense_18_loss: 3.4402 - val_loss: 3.2977 - val_dense_18_loss: 3.2977\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 4s 621ms/step - loss: 3.3549 - dense_18_loss: 3.3549 - val_loss: 3.0838 - val_dense_18_loss: 3.0838\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 3.3999 - dense_18_loss: 3.3999 - val_loss: 2.7360 - val_dense_18_loss: 2.7360\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 4s 622ms/step - loss: 3.3485 - dense_18_loss: 3.3485 - val_loss: 2.9560 - val_dense_18_loss: 2.9560\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 3.3259 - dense_18_loss: 3.3259 - val_loss: 2.7707 - val_dense_18_loss: 2.7707\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 3.3623 - dense_18_loss: 3.3623 - val_loss: 3.0802 - val_dense_18_loss: 3.0802\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 4s 617ms/step - loss: 3.2166 - dense_18_loss: 3.2166 - val_loss: 2.9244 - val_dense_18_loss: 2.9244\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "last 40 tokens of starting token:\n",
            "[14903 14903 14903 14903 14903 14903 14903 14903 24225 24225 24225 24225\n",
            " 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474 33474 33474\n",
            " 33474     0 14584 14584 14584 14584 14584 14584 14584 14584 14584 22520\n",
            " 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787]\n",
            "\n",
            "generated token:\n",
            "[14787, 14787, 14787, 14787, 793, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 30228, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 22686, 23123, 23123, 22686, 22686, 22686, 23123, 30228, 30228, 30228, 30228, 30228, 30228, 34955, 262, 3101, 18, 14584, 14584, 18, 18, 14584, 18, 18, 18, 18, 18, 2, 2, 2, 2, 2, 2, 2, 20, 20, 12, 12, 2, 9, 13, 18, 18, 18, 109, 134, 18, 109, 109, 18, 45, 2, 2, 2, 15, 31]\n",
            "\n",
            "6/6 [==============================] - 19s 4s/step - loss: 3.3257 - dense_18_loss: 3.3257 - val_loss: 3.0145 - val_dense_18_loss: 3.0145\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 3.3051 - dense_18_loss: 3.3051 - val_loss: 3.0270 - val_dense_18_loss: 3.0270\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 3.2559 - dense_18_loss: 3.2559 - val_loss: 2.8393 - val_dense_18_loss: 2.8393\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 3s 556ms/step - loss: 3.2250 - dense_18_loss: 3.2250 - val_loss: 2.8287 - val_dense_18_loss: 2.8287\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 4s 782ms/step - loss: 3.1120 - dense_18_loss: 3.1120 - val_loss: 2.7867 - val_dense_18_loss: 2.7867\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 3.1918 - dense_18_loss: 3.1918 - val_loss: 2.7313 - val_dense_18_loss: 2.7313\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 4s 699ms/step - loss: 3.0889 - dense_18_loss: 3.0889 - val_loss: 3.0252 - val_dense_18_loss: 3.0252\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 3s 548ms/step - loss: 3.1055 - dense_18_loss: 3.1055 - val_loss: 2.6464 - val_dense_18_loss: 2.6464\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 3.0816 - dense_18_loss: 3.0816 - val_loss: 2.7802 - val_dense_18_loss: 2.7802\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 4s 641ms/step - loss: 3.0515 - dense_18_loss: 3.0515 - val_loss: 2.8456 - val_dense_18_loss: 2.8456\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 2.9960 - dense_18_loss: 2.9960 - val_loss: 2.6506 - val_dense_18_loss: 2.6506\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 4s 618ms/step - loss: 2.9736 - dense_18_loss: 2.9736 - val_loss: 2.9449 - val_dense_18_loss: 2.9449\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 4s 685ms/step - loss: 2.9526 - dense_18_loss: 2.9526 - val_loss: 2.5073 - val_dense_18_loss: 2.5073\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 3s 510ms/step - loss: 2.9555 - dense_18_loss: 2.9555 - val_loss: 2.6233 - val_dense_18_loss: 2.6233\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 2.9846 - dense_18_loss: 2.9846 - val_loss: 2.6743 - val_dense_18_loss: 2.6743\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 3s 582ms/step - loss: 2.9942 - dense_18_loss: 2.9942 - val_loss: 2.5594 - val_dense_18_loss: 2.5594\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 4s 763ms/step - loss: 2.8933 - dense_18_loss: 2.8933 - val_loss: 2.5529 - val_dense_18_loss: 2.5529\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 4s 611ms/step - loss: 2.8541 - dense_18_loss: 2.8541 - val_loss: 2.4712 - val_dense_18_loss: 2.4712\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 2.8930 - dense_18_loss: 2.8930 - val_loss: 2.7113 - val_dense_18_loss: 2.7113\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 2.9213 - dense_18_loss: 2.9213 - val_loss: 2.4356 - val_dense_18_loss: 2.4356\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 2.9326 - dense_18_loss: 2.9326 - val_loss: 2.5328 - val_dense_18_loss: 2.5328\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 5s 830ms/step - loss: 2.7796 - dense_18_loss: 2.7796 - val_loss: 2.5634 - val_dense_18_loss: 2.5634\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 2.7986 - dense_18_loss: 2.7986 - val_loss: 2.5415 - val_dense_18_loss: 2.5415\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 4s 609ms/step - loss: 2.7245 - dense_18_loss: 2.7245 - val_loss: 2.1990 - val_dense_18_loss: 2.1990\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 3s 560ms/step - loss: 2.7515 - dense_18_loss: 2.7515 - val_loss: 2.5335 - val_dense_18_loss: 2.5335\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 2.7628 - dense_18_loss: 2.7628 - val_loss: 2.5221 - val_dense_18_loss: 2.5221\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 2.7307 - dense_18_loss: 2.7307 - val_loss: 2.1321 - val_dense_18_loss: 2.1321\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 3s 565ms/step - loss: 2.7347 - dense_18_loss: 2.7347 - val_loss: 2.4411 - val_dense_18_loss: 2.4411\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 2.7436 - dense_18_loss: 2.7436 - val_loss: 2.1225 - val_dense_18_loss: 2.1225\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 5s 798ms/step - loss: 2.7049 - dense_18_loss: 2.7049 - val_loss: 2.5480 - val_dense_18_loss: 2.5480\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 2.5093 - dense_18_loss: 2.5093 - val_loss: 2.4917 - val_dense_18_loss: 2.4917\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 2.5840 - dense_18_loss: 2.5840 - val_loss: 2.3994 - val_dense_18_loss: 2.3994\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 3s 567ms/step - loss: 2.6091 - dense_18_loss: 2.6091 - val_loss: 2.3427 - val_dense_18_loss: 2.3427\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 3s 562ms/step - loss: 2.6344 - dense_18_loss: 2.6344 - val_loss: 2.2840 - val_dense_18_loss: 2.2840\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 2.5596 - dense_18_loss: 2.5596 - val_loss: 2.3577 - val_dense_18_loss: 2.3577\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 2.5794 - dense_18_loss: 2.5794 - val_loss: 2.3248 - val_dense_18_loss: 2.3248\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 3s 596ms/step - loss: 2.5296 - dense_18_loss: 2.5296 - val_loss: 2.2134 - val_dense_18_loss: 2.2134\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 3s 515ms/step - loss: 2.5895 - dense_18_loss: 2.5895 - val_loss: 2.1118 - val_dense_18_loss: 2.1118\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 2.5539 - dense_18_loss: 2.5539 - val_loss: 2.3962 - val_dense_18_loss: 2.3962\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 4s 776ms/step - loss: 2.4247 - dense_18_loss: 2.4247 - val_loss: 2.3349 - val_dense_18_loss: 2.3349\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 2.4649 - dense_18_loss: 2.4649 - val_loss: 1.7855 - val_dense_18_loss: 1.7855\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 3s 579ms/step - loss: 2.4977 - dense_18_loss: 2.4977 - val_loss: 2.0669 - val_dense_18_loss: 2.0669\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 2.5067 - dense_18_loss: 2.5067 - val_loss: 2.2522 - val_dense_18_loss: 2.2522\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 4s 786ms/step - loss: 2.4107 - dense_18_loss: 2.4107 - val_loss: 2.0713 - val_dense_18_loss: 2.0713\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 3s 574ms/step - loss: 2.4403 - dense_18_loss: 2.4403 - val_loss: 2.1755 - val_dense_18_loss: 2.1755\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 2.4016 - dense_18_loss: 2.4016 - val_loss: 2.0350 - val_dense_18_loss: 2.0350\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 4s 698ms/step - loss: 2.3830 - dense_18_loss: 2.3830 - val_loss: 2.2732 - val_dense_18_loss: 2.2732\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 2.4288 - dense_18_loss: 2.4288 - val_loss: 2.0758 - val_dense_18_loss: 2.0758\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 4s 752ms/step - loss: 2.3751 - dense_18_loss: 2.3751 - val_loss: 2.0671 - val_dense_18_loss: 2.0671\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 4s 701ms/step - loss: 2.3100 - dense_18_loss: 2.3100 - val_loss: 1.8467 - val_dense_18_loss: 1.8467\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 2.3697 - dense_18_loss: 2.3697 - val_loss: 1.9944 - val_dense_18_loss: 1.9944\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 2.2807 - dense_18_loss: 2.2807 - val_loss: 2.0846 - val_dense_18_loss: 2.0846\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 2.3074 - dense_18_loss: 2.3074 - val_loss: 1.9816 - val_dense_18_loss: 1.9816\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 2.3072 - dense_18_loss: 2.3072 - val_loss: 1.9450 - val_dense_18_loss: 1.9450\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 2.2186 - dense_18_loss: 2.2186 - val_loss: 2.0609 - val_dense_18_loss: 2.0609\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 2.2958 - dense_18_loss: 2.2958 - val_loss: 2.0362 - val_dense_18_loss: 2.0362\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 2.2045 - dense_18_loss: 2.2045 - val_loss: 1.7783 - val_dense_18_loss: 1.7783\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 2.2052 - dense_18_loss: 2.2052 - val_loss: 1.7898 - val_dense_18_loss: 1.7898\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 2.2272 - dense_18_loss: 2.2272 - val_loss: 2.0071 - val_dense_18_loss: 2.0071\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 5s 808ms/step - loss: 2.1799 - dense_18_loss: 2.1799 - val_loss: 1.9039 - val_dense_18_loss: 1.9039\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 4s 612ms/step - loss: 2.1599 - dense_18_loss: 2.1599 - val_loss: 2.0112 - val_dense_18_loss: 2.0112\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 2.2075 - dense_18_loss: 2.2075 - val_loss: 1.9268 - val_dense_18_loss: 1.9268\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 2.2076 - dense_18_loss: 2.2076 - val_loss: 1.9785 - val_dense_18_loss: 1.9785\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 2.2131 - dense_18_loss: 2.2131 - val_loss: 1.7477 - val_dense_18_loss: 1.7477\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 3s 590ms/step - loss: 2.1816 - dense_18_loss: 2.1816 - val_loss: 2.0711 - val_dense_18_loss: 2.0711\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 4s 793ms/step - loss: 2.1325 - dense_18_loss: 2.1325 - val_loss: 1.7307 - val_dense_18_loss: 1.7307\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 2.1689 - dense_18_loss: 2.1689 - val_loss: 1.7512 - val_dense_18_loss: 1.7512\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 4s 670ms/step - loss: 2.1210 - dense_18_loss: 2.1210 - val_loss: 1.9459 - val_dense_18_loss: 1.9459\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 2.0824 - dense_18_loss: 2.0824 - val_loss: 1.9835 - val_dense_18_loss: 1.9835\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 2.0858 - dense_18_loss: 2.0858 - val_loss: 1.9214 - val_dense_18_loss: 1.9214\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 4s 677ms/step - loss: 2.0407 - dense_18_loss: 2.0407 - val_loss: 1.9280 - val_dense_18_loss: 1.9280\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 4s 620ms/step - loss: 2.0121 - dense_18_loss: 2.0121 - val_loss: 1.8671 - val_dense_18_loss: 1.8671\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 2.0728 - dense_18_loss: 2.0728 - val_loss: 1.7847 - val_dense_18_loss: 1.7847\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 3s 556ms/step - loss: 2.0224 - dense_18_loss: 2.0224 - val_loss: 1.7711 - val_dense_18_loss: 1.7711\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 2.0293 - dense_18_loss: 2.0293 - val_loss: 1.9686 - val_dense_18_loss: 1.9686\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 4s 739ms/step - loss: 1.9789 - dense_18_loss: 1.9789 - val_loss: 1.7950 - val_dense_18_loss: 1.7950\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 4s 698ms/step - loss: 1.9723 - dense_18_loss: 1.9723 - val_loss: 1.9824 - val_dense_18_loss: 1.9824\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 2.0412 - dense_18_loss: 2.0412 - val_loss: 1.7711 - val_dense_18_loss: 1.7711\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 2.0084 - dense_18_loss: 2.0084 - val_loss: 1.6523 - val_dense_18_loss: 1.6523\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 4s 792ms/step - loss: 1.9097 - dense_18_loss: 1.9097 - val_loss: 1.8406 - val_dense_18_loss: 1.8406\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 1.9604 - dense_18_loss: 1.9604 - val_loss: 1.7773 - val_dense_18_loss: 1.7773\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 1.9713 - dense_18_loss: 1.9713 - val_loss: 1.7211 - val_dense_18_loss: 1.7211\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 3s 547ms/step - loss: 1.9719 - dense_18_loss: 1.9719 - val_loss: 1.6017 - val_dense_18_loss: 1.6017\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 3s 541ms/step - loss: 1.9291 - dense_18_loss: 1.9291 - val_loss: 1.7775 - val_dense_18_loss: 1.7775\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 1.9347 - dense_18_loss: 1.9347 - val_loss: 1.6696 - val_dense_18_loss: 1.6696\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 5s 799ms/step - loss: 1.8960 - dense_18_loss: 1.8960 - val_loss: 1.6084 - val_dense_18_loss: 1.6084\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 3s 551ms/step - loss: 1.9021 - dense_18_loss: 1.9021 - val_loss: 1.7052 - val_dense_18_loss: 1.7052\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.9543 - dense_18_loss: 1.9543 - val_loss: 1.6048 - val_dense_18_loss: 1.6048\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 5s 813ms/step - loss: 1.8729 - dense_18_loss: 1.8729 - val_loss: 1.4954 - val_dense_18_loss: 1.4954\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 4s 614ms/step - loss: 1.8058 - dense_18_loss: 1.8058 - val_loss: 1.7972 - val_dense_18_loss: 1.7972\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 1.8854 - dense_18_loss: 1.8854 - val_loss: 1.7426 - val_dense_18_loss: 1.7426\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 4s 720ms/step - loss: 1.7997 - dense_18_loss: 1.7997 - val_loss: 1.6911 - val_dense_18_loss: 1.6911\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 1.9303 - dense_18_loss: 1.9303 - val_loss: 1.6869 - val_dense_18_loss: 1.6869\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 1.8731 - dense_18_loss: 1.8731 - val_loss: 1.6306 - val_dense_18_loss: 1.6306\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 3s 602ms/step - loss: 1.8392 - dense_18_loss: 1.8392 - val_loss: 1.5714 - val_dense_18_loss: 1.5714\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 3s 542ms/step - loss: 1.8633 - dense_18_loss: 1.8633 - val_loss: 1.6656 - val_dense_18_loss: 1.6656\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 4s 760ms/step - loss: 1.7934 - dense_18_loss: 1.7934 - val_loss: 1.6425 - val_dense_18_loss: 1.6425\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 1.8335 - dense_18_loss: 1.8335 - val_loss: 1.7286 - val_dense_18_loss: 1.7286\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 1.8710 - dense_18_loss: 1.8710 - val_loss: 1.6017 - val_dense_18_loss: 1.6017\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 4s 677ms/step - loss: 1.7861 - dense_18_loss: 1.7861 - val_loss: 1.5188 - val_dense_18_loss: 1.5188\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "last 40 tokens of starting token:\n",
            "[14903 14903 14903 14903 14903 14903 14903 14903 24225 24225 24225 24225\n",
            " 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474 33474 33474\n",
            " 33474     0 14584 14584 14584 14584 14584 14584 14584 14584 14584 22520\n",
            " 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787]\n",
            "\n",
            "generated token:\n",
            "[14787, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 30228, 30228, 30228, 30228, 30228, 34955, 262, 3101, 33, 10921, 33, 793, 793, 24045, 37085, 23405, 895, 33, 33, 895, 22058, 29955, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 23000, 22686, 22686, 22686, 22686, 22686, 22686, 35531, 128, 7414, 7414, 7414, 7414, 7521, 7521, 7521, 1883, 14472, 35355, 13, 13, 13, 2, 367, 2, 2, 2, 2, 2, 2]\n",
            "\n",
            "6/6 [==============================] - 21s 4s/step - loss: 1.7754 - dense_18_loss: 1.7754 - val_loss: 1.5427 - val_dense_18_loss: 1.5427\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 4s 794ms/step - loss: 1.7667 - dense_18_loss: 1.7667 - val_loss: 1.5284 - val_dense_18_loss: 1.5284\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 1.7707 - dense_18_loss: 1.7707 - val_loss: 1.5497 - val_dense_18_loss: 1.5497\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 3s 577ms/step - loss: 1.7749 - dense_18_loss: 1.7749 - val_loss: 1.6158 - val_dense_18_loss: 1.6158\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 1.7888 - dense_18_loss: 1.7888 - val_loss: 1.5019 - val_dense_18_loss: 1.5019\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 4s 788ms/step - loss: 1.7465 - dense_18_loss: 1.7465 - val_loss: 1.4906 - val_dense_18_loss: 1.4906\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 3s 563ms/step - loss: 1.7628 - dense_18_loss: 1.7628 - val_loss: 1.5328 - val_dense_18_loss: 1.5328\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.7493 - dense_18_loss: 1.7493 - val_loss: 1.6524 - val_dense_18_loss: 1.6524\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.7458 - dense_18_loss: 1.7458 - val_loss: 1.5946 - val_dense_18_loss: 1.5946\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 4s 735ms/step - loss: 1.7330 - dense_18_loss: 1.7330 - val_loss: 1.7075 - val_dense_18_loss: 1.7075\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 1.7077 - dense_18_loss: 1.7077 - val_loss: 1.4583 - val_dense_18_loss: 1.4583\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 3s 552ms/step - loss: 1.7285 - dense_18_loss: 1.7285 - val_loss: 1.5680 - val_dense_18_loss: 1.5680\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 1.7234 - dense_18_loss: 1.7234 - val_loss: 1.5587 - val_dense_18_loss: 1.5587\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 1.7433 - dense_18_loss: 1.7433 - val_loss: 1.4776 - val_dense_18_loss: 1.4776\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 4s 749ms/step - loss: 1.6427 - dense_18_loss: 1.6427 - val_loss: 1.5211 - val_dense_18_loss: 1.5211\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.6441 - dense_18_loss: 1.6441 - val_loss: 1.5822 - val_dense_18_loss: 1.5822\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 3s 515ms/step - loss: 1.7062 - dense_18_loss: 1.7062 - val_loss: 1.6081 - val_dense_18_loss: 1.6081\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.6942 - dense_18_loss: 1.6942 - val_loss: 1.5194 - val_dense_18_loss: 1.5194\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 1.6732 - dense_18_loss: 1.6732 - val_loss: 1.4812 - val_dense_18_loss: 1.4812\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 3s 508ms/step - loss: 1.6936 - dense_18_loss: 1.6936 - val_loss: 1.4960 - val_dense_18_loss: 1.4960\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.6568 - dense_18_loss: 1.6568 - val_loss: 1.5409 - val_dense_18_loss: 1.5409\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 5s 823ms/step - loss: 1.6326 - dense_18_loss: 1.6326 - val_loss: 1.4783 - val_dense_18_loss: 1.4783\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.6664 - dense_18_loss: 1.6664 - val_loss: 1.4456 - val_dense_18_loss: 1.4456\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.6331 - dense_18_loss: 1.6331 - val_loss: 1.4846 - val_dense_18_loss: 1.4846\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.6760 - dense_18_loss: 1.6760 - val_loss: 1.4846 - val_dense_18_loss: 1.4846\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 5s 806ms/step - loss: 1.6272 - dense_18_loss: 1.6272 - val_loss: 1.3122 - val_dense_18_loss: 1.3122\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 3s 585ms/step - loss: 1.6652 - dense_18_loss: 1.6652 - val_loss: 1.3611 - val_dense_18_loss: 1.3611\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 1.6278 - dense_18_loss: 1.6278 - val_loss: 1.5194 - val_dense_18_loss: 1.5194\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 1.6678 - dense_18_loss: 1.6678 - val_loss: 1.3411 - val_dense_18_loss: 1.3411\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.6692 - dense_18_loss: 1.6692 - val_loss: 1.3911 - val_dense_18_loss: 1.3911\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 5s 824ms/step - loss: 1.5765 - dense_18_loss: 1.5765 - val_loss: 1.3580 - val_dense_18_loss: 1.3580\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 3s 554ms/step - loss: 1.6114 - dense_18_loss: 1.6114 - val_loss: 1.3335 - val_dense_18_loss: 1.3335\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.6031 - dense_18_loss: 1.6031 - val_loss: 1.4561 - val_dense_18_loss: 1.4561\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.6020 - dense_18_loss: 1.6020 - val_loss: 1.4586 - val_dense_18_loss: 1.4586\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 4s 771ms/step - loss: 1.5703 - dense_18_loss: 1.5703 - val_loss: 1.4011 - val_dense_18_loss: 1.4011\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 4s 622ms/step - loss: 1.5668 - dense_18_loss: 1.5668 - val_loss: 1.3816 - val_dense_18_loss: 1.3816\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 4s 615ms/step - loss: 1.5585 - dense_18_loss: 1.5585 - val_loss: 1.4213 - val_dense_18_loss: 1.4213\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.5507 - dense_18_loss: 1.5507 - val_loss: 1.3140 - val_dense_18_loss: 1.3140\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.5955 - dense_18_loss: 1.5955 - val_loss: 1.4610 - val_dense_18_loss: 1.4610\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 3s 557ms/step - loss: 1.5676 - dense_18_loss: 1.5676 - val_loss: 1.3286 - val_dense_18_loss: 1.3286\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 4s 740ms/step - loss: 1.5396 - dense_18_loss: 1.5396 - val_loss: 1.1826 - val_dense_18_loss: 1.1826\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 1.5571 - dense_18_loss: 1.5571 - val_loss: 1.3056 - val_dense_18_loss: 1.3056\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.4915 - dense_18_loss: 1.4915 - val_loss: 1.2170 - val_dense_18_loss: 1.2170\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 3s 546ms/step - loss: 1.5468 - dense_18_loss: 1.5468 - val_loss: 1.3428 - val_dense_18_loss: 1.3428\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.5243 - dense_18_loss: 1.5243 - val_loss: 1.2740 - val_dense_18_loss: 1.2740\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.5251 - dense_18_loss: 1.5251 - val_loss: 1.3680 - val_dense_18_loss: 1.3680\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.5263 - dense_18_loss: 1.5263 - val_loss: 1.2522 - val_dense_18_loss: 1.2522\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.5199 - dense_18_loss: 1.5199 - val_loss: 1.3625 - val_dense_18_loss: 1.3625\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.5274 - dense_18_loss: 1.5274 - val_loss: 1.2770 - val_dense_18_loss: 1.2770\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.5016 - dense_18_loss: 1.5016 - val_loss: 1.3267 - val_dense_18_loss: 1.3267\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 1.5254 - dense_18_loss: 1.5254 - val_loss: 1.3929 - val_dense_18_loss: 1.3929\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 4s 755ms/step - loss: 1.4775 - dense_18_loss: 1.4775 - val_loss: 1.2817 - val_dense_18_loss: 1.2817\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.4904 - dense_18_loss: 1.4904 - val_loss: 1.2210 - val_dense_18_loss: 1.2210\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.5338 - dense_18_loss: 1.5338 - val_loss: 1.1396 - val_dense_18_loss: 1.1396\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.5072 - dense_18_loss: 1.5072 - val_loss: 1.2524 - val_dense_18_loss: 1.2524\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 1.4911 - dense_18_loss: 1.4911 - val_loss: 1.3854 - val_dense_18_loss: 1.3854\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 1.4873 - dense_18_loss: 1.4873 - val_loss: 1.1940 - val_dense_18_loss: 1.1940\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 4s 794ms/step - loss: 1.4281 - dense_18_loss: 1.4281 - val_loss: 1.2953 - val_dense_18_loss: 1.2953\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 3s 553ms/step - loss: 1.4696 - dense_18_loss: 1.4696 - val_loss: 1.4646 - val_dense_18_loss: 1.4646\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.4941 - dense_18_loss: 1.4941 - val_loss: 1.1639 - val_dense_18_loss: 1.1639\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 1.4392 - dense_18_loss: 1.4392 - val_loss: 1.1062 - val_dense_18_loss: 1.1062\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 3s 554ms/step - loss: 1.4323 - dense_18_loss: 1.4323 - val_loss: 1.0930 - val_dense_18_loss: 1.0930\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.4540 - dense_18_loss: 1.4540 - val_loss: 1.3071 - val_dense_18_loss: 1.3071\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 4s 765ms/step - loss: 1.3736 - dense_18_loss: 1.3736 - val_loss: 1.2735 - val_dense_18_loss: 1.2735\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 1.4407 - dense_18_loss: 1.4407 - val_loss: 1.0581 - val_dense_18_loss: 1.0581\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.3988 - dense_18_loss: 1.3988 - val_loss: 1.2579 - val_dense_18_loss: 1.2579\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 1.4461 - dense_18_loss: 1.4461 - val_loss: 1.0825 - val_dense_18_loss: 1.0825\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.4312 - dense_18_loss: 1.4312 - val_loss: 1.2499 - val_dense_18_loss: 1.2499\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 3s 535ms/step - loss: 1.3945 - dense_18_loss: 1.3945 - val_loss: 1.2564 - val_dense_18_loss: 1.2564\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 1.3924 - dense_18_loss: 1.3924 - val_loss: 1.1508 - val_dense_18_loss: 1.1508\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.4110 - dense_18_loss: 1.4110 - val_loss: 1.2424 - val_dense_18_loss: 1.2424\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 1.4163 - dense_18_loss: 1.4163 - val_loss: 1.3979 - val_dense_18_loss: 1.3979\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 1.4138 - dense_18_loss: 1.4138 - val_loss: 1.1851 - val_dense_18_loss: 1.1851\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.4036 - dense_18_loss: 1.4036 - val_loss: 1.1405 - val_dense_18_loss: 1.1405\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 1.4160 - dense_18_loss: 1.4160 - val_loss: 1.2397 - val_dense_18_loss: 1.2397\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 1.4248 - dense_18_loss: 1.4248 - val_loss: 1.1890 - val_dense_18_loss: 1.1890\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 4s 785ms/step - loss: 1.3580 - dense_18_loss: 1.3580 - val_loss: 1.1537 - val_dense_18_loss: 1.1537\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 1.3793 - dense_18_loss: 1.3793 - val_loss: 1.2026 - val_dense_18_loss: 1.2026\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 1.3993 - dense_18_loss: 1.3993 - val_loss: 1.1041 - val_dense_18_loss: 1.1041\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 4s 753ms/step - loss: 1.3253 - dense_18_loss: 1.3253 - val_loss: 1.2404 - val_dense_18_loss: 1.2404\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 3s 572ms/step - loss: 1.3264 - dense_18_loss: 1.3264 - val_loss: 1.2000 - val_dense_18_loss: 1.2000\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 1.3602 - dense_18_loss: 1.3602 - val_loss: 1.2386 - val_dense_18_loss: 1.2386\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.3863 - dense_18_loss: 1.3863 - val_loss: 1.2291 - val_dense_18_loss: 1.2291\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 1.3559 - dense_18_loss: 1.3559 - val_loss: 1.1894 - val_dense_18_loss: 1.1894\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.3582 - dense_18_loss: 1.3582 - val_loss: 1.1755 - val_dense_18_loss: 1.1755\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.3958 - dense_18_loss: 1.3958 - val_loss: 1.1308 - val_dense_18_loss: 1.1308\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.3254 - dense_18_loss: 1.3254 - val_loss: 1.2340 - val_dense_18_loss: 1.2340\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.3383 - dense_18_loss: 1.3383 - val_loss: 1.1070 - val_dense_18_loss: 1.1070\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.3523 - dense_18_loss: 1.3523 - val_loss: 1.0861 - val_dense_18_loss: 1.0861\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 5s 849ms/step - loss: 1.3204 - dense_18_loss: 1.3204 - val_loss: 1.1709 - val_dense_18_loss: 1.1709\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 1.3166 - dense_18_loss: 1.3166 - val_loss: 1.1145 - val_dense_18_loss: 1.1145\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 3s 569ms/step - loss: 1.3590 - dense_18_loss: 1.3590 - val_loss: 1.0952 - val_dense_18_loss: 1.0952\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 1.3609 - dense_18_loss: 1.3609 - val_loss: 1.2446 - val_dense_18_loss: 1.2446\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.3214 - dense_18_loss: 1.3214 - val_loss: 1.2032 - val_dense_18_loss: 1.2032\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.3182 - dense_18_loss: 1.3182 - val_loss: 1.1129 - val_dense_18_loss: 1.1129\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 3s 576ms/step - loss: 1.3175 - dense_18_loss: 1.3175 - val_loss: 1.2254 - val_dense_18_loss: 1.2254\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 1.3302 - dense_18_loss: 1.3302 - val_loss: 1.0777 - val_dense_18_loss: 1.0777\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 4s 769ms/step - loss: 1.2991 - dense_18_loss: 1.2991 - val_loss: 1.1611 - val_dense_18_loss: 1.1611\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 3s 555ms/step - loss: 1.3314 - dense_18_loss: 1.3314 - val_loss: 1.0066 - val_dense_18_loss: 1.0066\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.3063 - dense_18_loss: 1.3063 - val_loss: 1.1011 - val_dense_18_loss: 1.1011\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "last 40 tokens of starting token:\n",
            "[14903 14903 14903 14903 14903 14903 14903 14903 24225 24225 24225 24225\n",
            " 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474 33474 33474\n",
            " 33474     0 14584 14584 14584 14584 14584 14584 14584 14584 14584 22520\n",
            " 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787]\n",
            "\n",
            "generated token:\n",
            "[23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 30228, 34955, 262, 262, 262, 3101, 33, 10921, 33, 33, 33, 793, 793, 24045, 24045, 24045, 24045, 24045, 24045, 37085, 23405, 895, 895, 895, 22058, 29955, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 35531, 128, 7414, 1883, 7521, 156, 156, 625, 625, 26, 7414, 7414, 7414, 14472, 14472, 14472, 14472, 14472, 35355, 1857, 7436, 10767, 42, 42, 10767, 2, 42, 10767, 0, 42, 10767, 50, 50]\n",
            "\n",
            "6/6 [==============================] - 21s 4s/step - loss: 1.2981 - dense_18_loss: 1.2981 - val_loss: 1.0394 - val_dense_18_loss: 1.0394\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 1.3087 - dense_18_loss: 1.3087 - val_loss: 1.0641 - val_dense_18_loss: 1.0641\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 4s 760ms/step - loss: 1.2958 - dense_18_loss: 1.2958 - val_loss: 1.0687 - val_dense_18_loss: 1.0687\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 1.2614 - dense_18_loss: 1.2614 - val_loss: 1.0919 - val_dense_18_loss: 1.0919\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.2878 - dense_18_loss: 1.2878 - val_loss: 1.1344 - val_dense_18_loss: 1.1344\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.2845 - dense_18_loss: 1.2845 - val_loss: 1.0289 - val_dense_18_loss: 1.0289\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 1.2798 - dense_18_loss: 1.2798 - val_loss: 1.1487 - val_dense_18_loss: 1.1487\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 1.2617 - dense_18_loss: 1.2617 - val_loss: 1.1290 - val_dense_18_loss: 1.1290\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 4s 769ms/step - loss: 1.2567 - dense_18_loss: 1.2567 - val_loss: 1.2043 - val_dense_18_loss: 1.2043\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 3s 577ms/step - loss: 1.2617 - dense_18_loss: 1.2617 - val_loss: 1.1383 - val_dense_18_loss: 1.1383\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 1.2806 - dense_18_loss: 1.2806 - val_loss: 1.0938 - val_dense_18_loss: 1.0938\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 4s 620ms/step - loss: 1.2432 - dense_18_loss: 1.2432 - val_loss: 1.0076 - val_dense_18_loss: 1.0076\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 3s 521ms/step - loss: 1.3010 - dense_18_loss: 1.3010 - val_loss: 1.1574 - val_dense_18_loss: 1.1574\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 4s 612ms/step - loss: 1.2138 - dense_18_loss: 1.2138 - val_loss: 0.9614 - val_dense_18_loss: 0.9614\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.2393 - dense_18_loss: 1.2393 - val_loss: 1.1482 - val_dense_18_loss: 1.1482\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 3s 520ms/step - loss: 1.2645 - dense_18_loss: 1.2645 - val_loss: 1.0608 - val_dense_18_loss: 1.0608\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 4s 599ms/step - loss: 1.2590 - dense_18_loss: 1.2590 - val_loss: 1.0109 - val_dense_18_loss: 1.0109\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.2227 - dense_18_loss: 1.2227 - val_loss: 1.0932 - val_dense_18_loss: 1.0932\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 4s 776ms/step - loss: 1.1988 - dense_18_loss: 1.1988 - val_loss: 0.8785 - val_dense_18_loss: 0.8785\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 3s 550ms/step - loss: 1.2302 - dense_18_loss: 1.2302 - val_loss: 1.1104 - val_dense_18_loss: 1.1104\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 4s 618ms/step - loss: 1.1888 - dense_18_loss: 1.1888 - val_loss: 1.0359 - val_dense_18_loss: 1.0359\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.2459 - dense_18_loss: 1.2459 - val_loss: 1.0060 - val_dense_18_loss: 1.0060\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.2075 - dense_18_loss: 1.2075 - val_loss: 1.0501 - val_dense_18_loss: 1.0501\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.2287 - dense_18_loss: 1.2287 - val_loss: 1.0945 - val_dense_18_loss: 1.0945\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 1.2507 - dense_18_loss: 1.2507 - val_loss: 1.0058 - val_dense_18_loss: 1.0058\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.2601 - dense_18_loss: 1.2601 - val_loss: 1.1342 - val_dense_18_loss: 1.1342\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 3s 529ms/step - loss: 1.1934 - dense_18_loss: 1.1934 - val_loss: 1.0611 - val_dense_18_loss: 1.0611\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 5s 814ms/step - loss: 1.1842 - dense_18_loss: 1.1842 - val_loss: 1.1761 - val_dense_18_loss: 1.1761\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 1.1574 - dense_18_loss: 1.1574 - val_loss: 1.0390 - val_dense_18_loss: 1.0390\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.2201 - dense_18_loss: 1.2201 - val_loss: 1.0214 - val_dense_18_loss: 1.0214\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 3s 513ms/step - loss: 1.2030 - dense_18_loss: 1.2030 - val_loss: 1.0701 - val_dense_18_loss: 1.0701\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.2036 - dense_18_loss: 1.2036 - val_loss: 0.9889 - val_dense_18_loss: 0.9889\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 1.2058 - dense_18_loss: 1.2058 - val_loss: 0.9931 - val_dense_18_loss: 0.9931\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 3s 538ms/step - loss: 1.2025 - dense_18_loss: 1.2025 - val_loss: 1.0238 - val_dense_18_loss: 1.0238\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 1.1909 - dense_18_loss: 1.1909 - val_loss: 0.9592 - val_dense_18_loss: 0.9592\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.1643 - dense_18_loss: 1.1643 - val_loss: 1.0306 - val_dense_18_loss: 1.0306\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 5s 825ms/step - loss: 1.1358 - dense_18_loss: 1.1358 - val_loss: 0.9832 - val_dense_18_loss: 0.9832\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 1.1788 - dense_18_loss: 1.1788 - val_loss: 1.0115 - val_dense_18_loss: 1.0115\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.1865 - dense_18_loss: 1.1865 - val_loss: 1.1021 - val_dense_18_loss: 1.1021\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 1.1720 - dense_18_loss: 1.1720 - val_loss: 0.9398 - val_dense_18_loss: 0.9398\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 3s 532ms/step - loss: 1.1807 - dense_18_loss: 1.1807 - val_loss: 0.8859 - val_dense_18_loss: 0.8859\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.1783 - dense_18_loss: 1.1783 - val_loss: 0.8632 - val_dense_18_loss: 0.8632\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 3s 561ms/step - loss: 1.1610 - dense_18_loss: 1.1610 - val_loss: 0.9519 - val_dense_18_loss: 0.9519\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 3s 544ms/step - loss: 1.1660 - dense_18_loss: 1.1660 - val_loss: 0.9290 - val_dense_18_loss: 0.9290\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 3s 517ms/step - loss: 1.1501 - dense_18_loss: 1.1501 - val_loss: 0.8904 - val_dense_18_loss: 0.8904\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.1411 - dense_18_loss: 1.1411 - val_loss: 0.8161 - val_dense_18_loss: 0.8161\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 3s 533ms/step - loss: 1.1507 - dense_18_loss: 1.1507 - val_loss: 0.9643 - val_dense_18_loss: 0.9643\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 4s 805ms/step - loss: 1.1142 - dense_18_loss: 1.1142 - val_loss: 0.9741 - val_dense_18_loss: 0.9741\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 4s 612ms/step - loss: 1.0969 - dense_18_loss: 1.0969 - val_loss: 0.8909 - val_dense_18_loss: 0.8909\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 1.1386 - dense_18_loss: 1.1386 - val_loss: 0.9367 - val_dense_18_loss: 0.9367\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 3s 582ms/step - loss: 1.1358 - dense_18_loss: 1.1358 - val_loss: 0.9789 - val_dense_18_loss: 0.9789\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 3s 516ms/step - loss: 1.1353 - dense_18_loss: 1.1353 - val_loss: 0.9310 - val_dense_18_loss: 0.9310\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 3s 512ms/step - loss: 1.1396 - dense_18_loss: 1.1396 - val_loss: 1.0130 - val_dense_18_loss: 1.0130\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 3s 539ms/step - loss: 1.1262 - dense_18_loss: 1.1262 - val_loss: 0.9339 - val_dense_18_loss: 0.9339\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.1154 - dense_18_loss: 1.1154 - val_loss: 0.9627 - val_dense_18_loss: 0.9627\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 1.1181 - dense_18_loss: 1.1181 - val_loss: 0.9256 - val_dense_18_loss: 0.9256\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.1270 - dense_18_loss: 1.1270 - val_loss: 0.8516 - val_dense_18_loss: 0.8516\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 3s 549ms/step - loss: 1.1204 - dense_18_loss: 1.1204 - val_loss: 0.8492 - val_dense_18_loss: 0.8492\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 1.1079 - dense_18_loss: 1.1079 - val_loss: 0.8888 - val_dense_18_loss: 0.8888\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.1217 - dense_18_loss: 1.1217 - val_loss: 0.9573 - val_dense_18_loss: 0.9573\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 3s 578ms/step - loss: 1.1451 - dense_18_loss: 1.1451 - val_loss: 0.9470 - val_dense_18_loss: 0.9470\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.1263 - dense_18_loss: 1.1263 - val_loss: 0.9206 - val_dense_18_loss: 0.9206\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.1371 - dense_18_loss: 1.1371 - val_loss: 0.9689 - val_dense_18_loss: 0.9689\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 1.1075 - dense_18_loss: 1.1075 - val_loss: 0.8707 - val_dense_18_loss: 0.8707\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 1.1223 - dense_18_loss: 1.1223 - val_loss: 0.9119 - val_dense_18_loss: 0.9119\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.1243 - dense_18_loss: 1.1243 - val_loss: 1.0301 - val_dense_18_loss: 1.0301\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 5s 863ms/step - loss: 1.0919 - dense_18_loss: 1.0919 - val_loss: 0.9664 - val_dense_18_loss: 0.9664\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 4s 625ms/step - loss: 1.0845 - dense_18_loss: 1.0845 - val_loss: 0.8907 - val_dense_18_loss: 0.8907\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 4s 615ms/step - loss: 1.0479 - dense_18_loss: 1.0479 - val_loss: 0.9057 - val_dense_18_loss: 0.9057\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 3s 573ms/step - loss: 1.0962 - dense_18_loss: 1.0962 - val_loss: 0.8584 - val_dense_18_loss: 0.8584\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 1.0988 - dense_18_loss: 1.0988 - val_loss: 0.9545 - val_dense_18_loss: 0.9545\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 3s 519ms/step - loss: 1.0811 - dense_18_loss: 1.0811 - val_loss: 0.8342 - val_dense_18_loss: 0.8342\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 3s 536ms/step - loss: 1.0751 - dense_18_loss: 1.0751 - val_loss: 0.9680 - val_dense_18_loss: 0.9680\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 3s 545ms/step - loss: 1.0966 - dense_18_loss: 1.0966 - val_loss: 0.9316 - val_dense_18_loss: 0.9316\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.1006 - dense_18_loss: 1.1006 - val_loss: 0.9302 - val_dense_18_loss: 0.9302\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 1.0485 - dense_18_loss: 1.0485 - val_loss: 0.8996 - val_dense_18_loss: 0.8996\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 5s 812ms/step - loss: 1.0456 - dense_18_loss: 1.0456 - val_loss: 0.8290 - val_dense_18_loss: 0.8290\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 3s 528ms/step - loss: 1.0529 - dense_18_loss: 1.0529 - val_loss: 0.8214 - val_dense_18_loss: 0.8214\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 3s 570ms/step - loss: 1.0586 - dense_18_loss: 1.0586 - val_loss: 0.9185 - val_dense_18_loss: 0.9185\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.0656 - dense_18_loss: 1.0656 - val_loss: 1.0426 - val_dense_18_loss: 1.0426\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 4s 750ms/step - loss: 1.0413 - dense_18_loss: 1.0413 - val_loss: 0.9139 - val_dense_18_loss: 0.9139\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 1.0272 - dense_18_loss: 1.0272 - val_loss: 0.8445 - val_dense_18_loss: 0.8445\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 1.0616 - dense_18_loss: 1.0616 - val_loss: 0.7588 - val_dense_18_loss: 0.7588\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 3s 555ms/step - loss: 1.0724 - dense_18_loss: 1.0724 - val_loss: 0.9280 - val_dense_18_loss: 0.9280\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.0446 - dense_18_loss: 1.0446 - val_loss: 0.7245 - val_dense_18_loss: 0.7245\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.0600 - dense_18_loss: 1.0600 - val_loss: 0.8721 - val_dense_18_loss: 0.8721\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 3s 537ms/step - loss: 1.0477 - dense_18_loss: 1.0477 - val_loss: 0.8755 - val_dense_18_loss: 0.8755\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 4s 770ms/step - loss: 1.0214 - dense_18_loss: 1.0214 - val_loss: 0.8318 - val_dense_18_loss: 0.8318\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 3s 524ms/step - loss: 1.0401 - dense_18_loss: 1.0401 - val_loss: 0.9589 - val_dense_18_loss: 0.9589\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 3s 583ms/step - loss: 1.0377 - dense_18_loss: 1.0377 - val_loss: 1.0000 - val_dense_18_loss: 1.0000\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 3s 543ms/step - loss: 1.0280 - dense_18_loss: 1.0280 - val_loss: 0.8387 - val_dense_18_loss: 0.8387\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 3s 523ms/step - loss: 1.0317 - dense_18_loss: 1.0317 - val_loss: 0.9433 - val_dense_18_loss: 0.9433\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 3s 525ms/step - loss: 1.0443 - dense_18_loss: 1.0443 - val_loss: 0.8737 - val_dense_18_loss: 0.8737\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 3s 518ms/step - loss: 1.0566 - dense_18_loss: 1.0566 - val_loss: 0.8780 - val_dense_18_loss: 0.8780\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 4s 794ms/step - loss: 1.0018 - dense_18_loss: 1.0018 - val_loss: 0.7908 - val_dense_18_loss: 0.7908\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 3s 526ms/step - loss: 1.0297 - dense_18_loss: 1.0297 - val_loss: 0.9719 - val_dense_18_loss: 0.9719\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 3s 514ms/step - loss: 1.0069 - dense_18_loss: 1.0069 - val_loss: 0.7724 - val_dense_18_loss: 0.7724\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 3s 540ms/step - loss: 1.0373 - dense_18_loss: 1.0373 - val_loss: 0.9048 - val_dense_18_loss: 0.9048\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 3s 530ms/step - loss: 1.0052 - dense_18_loss: 1.0052 - val_loss: 0.7622 - val_dense_18_loss: 0.7622\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 3s 522ms/step - loss: 1.0596 - dense_18_loss: 1.0596 - val_loss: 0.8225 - val_dense_18_loss: 0.8225\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "last 40 tokens of starting token:\n",
            "[14903 14903 14903 14903 14903 14903 14903 14903 24225 24225 24225 24225\n",
            " 30462 30462 30462 30462 33474 33474 33474 33474 33474 33474 33474 33474\n",
            " 33474     0 14584 14584 14584 14584 14584 14584 14584 14584 14584 22520\n",
            " 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787 14787\n",
            " 14787 14787]\n",
            "\n",
            "generated token:\n",
            "[14787, 14787, 14787, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 23123, 30228, 30228, 30228, 30228, 30228, 30228, 30228, 34955, 262, 262, 262, 3101, 33, 10921, 33, 33, 793, 793, 793, 24045, 24045, 24045, 24045, 24045, 24045, 37085, 23405, 895, 895, 22058, 29955, 29955, 29955, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 22686, 35531, 128, 7414, 1883, 1883, 7521, 156, 625, 26, 7414, 7414, 7414, 7414, 7414]\n",
            "\n",
            "6/6 [==============================] - 20s 4s/step - loss: 1.0030 - dense_18_loss: 1.0030 - val_loss: 0.8730 - val_dense_18_loss: 0.8730\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 562,
              "height": 454
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result stored in /content/drive/MyDrive/5 - Music Generation by GPT/output/MuGenTransformer_v3_500321683977257_16v2f/\n"
          ]
        }
      ],
      "source": [
        "epochs = 500\n",
        "batchsize = 32\n",
        "output_path = f\"/content/drive/MyDrive/5 - Music Generation by GPT/output/MuGenTransformer_v3_{epochs}{batchsize}{int(time.time())}_16v2f/\"\n",
        "\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(all_song_tokenised, batchsize, sequence_length)\n",
        "my_validation_batch_generator = My_Custom_Generator(all_song_tokenised, batchsize, sequence_length, val_split=0.1)\n",
        "\n",
        "\n",
        "# if not os.path.exists(output_path):\n",
        "#     os.mkdir(output_path)\n",
        "\n",
        "# model.load_weights(\"./output/train_multilabel_v3_1_4001000_16th/music-gen-weight.hdf5\")\n",
        "\n",
        "weight_path = output_path + \"music-gen-weight.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    weight_path,\n",
        "    monitor='loss',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "callbacks_list = [checkpoint,gen_callback]\n",
        "# history = model.fit(network_input,\n",
        "#                     network_output, \n",
        "#                     epochs=epochs, \n",
        "#                     batch_size=batchsize, \n",
        "#                     callbacks=callbacks_list,\n",
        "#                     validation_split=0.1,\n",
        "#                    shuffle=True)\n",
        "\n",
        "history = model.fit(x = my_training_batch_generator,\n",
        "                    callbacks = callbacks_list,                    \n",
        "                   epochs = epochs,\n",
        "                   verbose = 1,\n",
        "                   validation_data = my_validation_batch_generator)\n",
        "\n",
        "train_loss += history.history['loss']\n",
        "val_loss += history.history['val_loss']\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'validation_loss'], loc='upper right')\n",
        "plt.savefig(output_path + 'loss.png')\n",
        "plt.show()\n",
        "print(\"Result stored in {}\".format(output_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUZhPA7e2yTY"
      },
      "source": [
        "## Inference\n",
        "Get a random seq from a random song from input. \n",
        "Then predict from it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eIkpztU2yTY",
        "outputId": "f18c8ec1-1db0-4edc-ef40-bffc6240bfac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 1 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 2 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 3 notes\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "generated 4 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 5 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 6 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 7 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 8 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 9 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 10 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 11 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 12 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 13 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 14 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 15 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 16 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 17 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 18 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 19 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 20 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 21 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 22 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 23 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 24 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 25 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 26 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 27 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 28 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 29 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 30 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 31 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 32 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 33 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 34 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 35 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 36 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 37 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 38 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 39 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 40 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 41 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 42 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 43 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 44 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 45 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 46 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 47 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 48 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 49 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 50 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 51 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 52 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 53 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 54 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 55 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 56 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 57 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 58 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 59 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 60 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 61 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 62 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 63 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 64 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 65 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 66 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 67 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 68 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 69 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 70 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 71 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 72 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 73 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 74 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 75 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 76 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 77 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 78 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 79 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 80 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 81 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 82 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 83 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 84 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 85 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 86 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 87 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 88 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 89 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 90 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 91 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 92 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 93 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 94 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 95 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 96 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 97 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 98 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 99 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 100 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 101 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 102 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 103 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 104 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 105 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 106 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 107 notes\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "generated 108 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 109 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 110 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 111 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 112 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 113 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 114 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 115 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 116 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 117 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 118 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 119 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 120 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 121 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 122 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 123 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 124 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 125 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 126 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 127 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 128 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 129 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 130 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 131 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 132 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 133 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 134 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 135 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 136 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 137 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 138 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 139 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 140 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 141 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 142 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 143 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 144 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 145 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 146 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 147 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 148 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 149 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 150 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 151 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 152 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 153 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 154 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 155 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 156 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 157 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 158 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 159 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 160 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 161 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 162 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 163 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 164 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 165 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 166 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 167 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 168 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 169 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 170 notes\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "generated 171 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 172 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 173 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 174 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 175 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 176 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 177 notes\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "generated 178 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 179 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 180 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 181 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 182 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 183 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 184 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 185 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 186 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 187 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 188 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 189 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 190 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 191 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 192 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 193 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 194 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 195 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 196 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 197 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 198 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 199 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 200 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 201 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 202 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 203 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 204 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 205 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 206 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 207 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 208 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 209 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 210 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 211 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 212 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 213 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 214 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 215 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 216 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 217 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 218 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 219 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 220 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 221 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 222 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 223 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 224 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 225 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 226 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 227 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 228 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 229 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 230 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 231 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 232 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 233 notes\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "generated 234 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 235 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 236 notes\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "generated 237 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 238 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 239 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 240 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 241 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 242 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 243 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 244 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 245 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 246 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 247 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 248 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 249 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 250 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 251 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 252 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 253 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 254 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 255 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 256 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 257 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 258 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 259 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 260 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 261 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 262 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 263 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 264 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 265 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 266 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 267 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 268 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 269 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 270 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 271 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 272 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 273 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 274 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 275 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 276 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 277 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 278 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 279 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 280 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 281 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 282 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 283 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 284 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 285 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 286 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 287 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 288 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 289 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 290 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 291 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 292 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 293 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 294 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 295 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 296 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 297 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 298 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 299 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 300 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 301 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 302 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 303 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 304 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 305 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 306 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 307 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 308 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 309 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 310 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 311 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 312 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 313 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 314 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 315 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 316 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 317 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 318 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 319 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 320 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 321 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 322 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 323 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 324 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 325 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 326 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 327 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 328 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 329 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 330 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 331 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 332 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 333 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 334 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 335 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 336 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 337 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 338 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 339 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 340 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 341 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 342 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 343 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 344 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 345 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 346 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 347 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 348 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 349 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 350 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 351 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 352 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 353 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 354 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 355 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 356 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 357 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 358 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 359 notes\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "generated 360 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 361 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 362 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 363 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 364 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 365 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 366 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 367 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 368 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 369 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 370 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 371 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 372 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 373 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 374 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 375 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 376 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 377 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 378 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 379 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 380 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 381 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 382 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 383 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 384 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 385 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 386 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 387 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 388 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 389 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 390 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 391 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 392 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 393 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 394 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 395 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 396 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 397 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 398 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 399 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 400 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 401 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 402 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 403 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 404 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 405 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 406 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 407 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 408 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 409 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 410 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 411 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 412 notes\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "generated 413 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 414 notes\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "generated 415 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 416 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 417 notes\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "generated 418 notes\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "generated 419 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 420 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 421 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 422 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 423 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 424 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 425 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 426 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 427 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 428 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 429 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 430 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 431 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 432 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 433 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 434 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 435 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 436 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 437 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 438 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 439 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 440 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 441 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 442 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 443 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 444 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 445 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 446 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 447 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 448 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 449 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 450 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 451 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 452 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 453 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 454 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 455 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 456 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 457 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 458 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 459 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 460 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 461 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 462 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 463 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 464 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 465 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 466 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 467 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 468 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 469 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 470 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 471 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 472 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 473 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 474 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 475 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 476 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 477 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 478 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 479 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 480 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 481 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 482 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 483 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 484 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 485 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 486 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 487 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 488 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 489 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 490 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 491 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 492 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 493 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 494 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 495 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 496 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 497 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 498 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 499 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 500 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 501 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 502 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 503 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 504 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 505 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 506 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 507 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 508 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 509 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 510 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 511 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 512 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 513 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 514 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 515 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 516 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 517 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 518 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 519 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 520 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 521 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 522 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 523 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 524 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 525 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 526 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 527 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 528 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 529 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 530 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 531 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 532 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 533 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 534 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 535 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 536 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 537 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 538 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 539 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 540 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 541 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 542 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 543 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 544 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 545 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 546 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 547 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 548 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 549 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 550 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 551 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 552 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 553 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 554 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 555 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 556 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 557 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 558 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 559 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 560 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 561 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 562 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 563 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 564 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 565 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 566 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 567 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 568 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 569 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 570 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 571 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 572 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 573 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 574 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 575 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 576 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 577 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 578 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 579 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 580 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 581 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 582 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 583 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 584 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 585 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 586 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 587 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 588 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 589 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 590 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 591 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 592 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 593 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 594 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 595 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 596 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 597 notes\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "generated 598 notes\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "generated 599 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 600 notes\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "generated 601 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 602 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 603 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 604 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 605 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 606 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 607 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 608 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 609 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 610 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 611 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 612 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 613 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 614 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 615 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 616 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 617 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 618 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 619 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 620 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 621 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 622 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 623 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 624 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 625 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 626 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 627 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 628 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 629 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 630 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 631 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 632 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 633 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 634 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 635 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 636 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 637 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 638 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 639 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 640 notes\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "generated 641 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 642 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 643 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 644 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 645 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 646 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 647 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 648 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 649 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 650 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 651 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 652 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 653 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 654 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 655 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 656 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 657 notes\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "generated 658 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 659 notes\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "generated 660 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 661 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 662 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 663 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 664 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 665 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 666 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 667 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 668 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 669 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 670 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 671 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 672 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 673 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 674 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 675 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 676 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 677 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 678 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 679 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 680 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 681 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 682 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 683 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 684 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 685 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 686 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 687 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 688 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 689 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 690 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 691 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 692 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 693 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 694 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 695 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 696 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 697 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 698 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 699 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 700 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 701 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 702 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 703 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 704 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 705 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 706 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 707 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 708 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 709 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 710 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 711 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 712 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 713 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 714 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 715 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 716 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 717 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 718 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 719 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 720 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 721 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 722 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 723 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 724 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 725 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 726 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 727 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 728 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 729 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 730 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 731 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 732 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 733 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 734 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 735 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 736 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 737 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 738 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 739 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 740 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 741 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 742 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 743 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 744 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 745 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 746 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 747 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 748 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 749 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 750 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 751 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 752 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 753 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 754 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 755 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 756 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 757 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 758 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 759 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 760 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 761 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 762 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 763 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 764 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 765 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 766 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 767 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 768 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 769 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 770 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 771 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 772 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 773 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 774 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 775 notes\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "generated 776 notes\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "generated 777 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 778 notes\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "generated 779 notes\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "generated 780 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 781 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 782 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 783 notes\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "generated 784 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 785 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 786 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 787 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 788 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 789 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 790 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 791 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 792 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 793 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 794 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 795 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 796 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 797 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 798 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 799 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 800 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 801 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 802 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 803 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 804 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 805 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 806 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 807 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 808 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 809 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 810 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 811 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 812 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 813 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 814 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 815 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 816 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 817 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 818 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 819 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 820 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 821 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 822 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 823 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 824 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 825 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 826 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 827 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 828 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 829 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 830 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 831 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 832 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 833 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 834 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 835 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 836 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 837 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 838 notes\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "generated 839 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 840 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 841 notes\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "generated 842 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 843 notes\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "generated 844 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 845 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 846 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 847 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 848 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 849 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 850 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 851 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 852 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 853 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 854 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 855 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 856 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 857 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 858 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 859 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 860 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 861 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 862 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 863 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 864 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 865 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 866 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 867 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 868 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 869 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 870 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 871 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 872 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 873 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 874 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 875 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 876 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 877 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 878 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 879 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 880 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 881 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 882 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 883 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 884 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 885 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 886 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 887 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 888 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 889 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 890 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 891 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 892 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 893 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 894 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 895 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 896 notes\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "generated 897 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 898 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 899 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 900 notes\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "generated 901 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 902 notes\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "generated 903 notes\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "generated 904 notes\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "generated 905 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 906 notes\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "generated 907 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 908 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 909 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 910 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 911 notes\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "generated 912 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 913 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 914 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 915 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 916 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 917 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 918 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 919 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 920 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 921 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 922 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 923 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 924 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 925 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 926 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 927 notes\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "generated 928 notes\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "generated 929 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 930 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 931 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 932 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 933 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 934 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 935 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 936 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 937 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 938 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 939 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 940 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 941 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 942 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 943 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 944 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 945 notes\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "generated 946 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 947 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 948 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 949 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 950 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 951 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 952 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 953 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 954 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 955 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 956 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 957 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 958 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 959 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 960 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 961 notes\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "generated 962 notes\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "generated 963 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 964 notes\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "generated 965 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 966 notes\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "generated 967 notes\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "generated 968 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 969 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 970 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 971 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 972 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 973 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 974 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 975 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 976 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 977 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 978 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 979 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 980 notes\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "generated 981 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 982 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 983 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 984 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 985 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 986 notes\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "generated 987 notes\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "generated 988 notes\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "generated 989 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 990 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 991 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 992 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 993 notes\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "generated 994 notes\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "generated 995 notes\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "generated 996 notes\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "generated 997 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 998 notes\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "generated 999 notes\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "generated 1000 notes\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "generated 1001 notes\n",
            "[(42, 50, 57), (42, 50, 57, 62, 69), (42, 50, 57, 62, 69), (42, 50, 57, 62, 66, 69), (42, 50, 57, 62, 66, 69), (42, 50, 57, 62, 66, 69), (63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (51, 57, 60, 63, 66), (51, 63, 66), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67, 69), (52, 59, 62, 67, 69), (55, 63, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71, 73), (45, 55, 61, 63, 67, 71, 73), (45, 55, 61, 63, 67, 71, 73), (62, 67, 74), (62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74, 86), (50, 62, 67, 74, 86), (50, 62, 67, 74, 86), (50, 62), (50, 62), (50, 62), (50,), '<UNK>', (50, 62, 80, 82, 86), (50, 62, 80, 82, 86), (50, 62, 74, 80, 82, 86), (50, 62, 74, 80, 82, 86), '<UNK>', (50,), (50,), (50, 62), (50,), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), '<UNK>', (43, 49, 50, 62, 74, 78, 80, 86), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 62, 76), (43, 50, 57, 59, 60, 62, 76), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 55, 57, 59, 60, 62, 76, 78, 79), (43, 50, 55, 57, 59, 60, 62, 76, 78, 79), (43, 50, 55, 57, 59, 60, 61, 62, 64, 67, 70, 76, 78, 79), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78), (55, 61, 64, 67, 70, 73, 76, 78, 79), (54, 55, 61, 64, 67, 69, 70, 73, 74, 76, 78, 79), (54, 60, 62, 69, 74, 81), (54, 60, 62), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (54, 60, 62, 72, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 66, 74), (52, 60, 62, 66, 74), (52, 60, 62, 66, 74), (52, 60, 62, 66, 74), (52, 60, 62, 66, 74), (52, 60, 62, 66, 74), (52, 60, 62, 66, 74), (53, 60, 65, 68), (53, 60, 65, 68), (60, 65, 68), (52, 60, 65, 68), (52, 60, 65, 68), (52, 60, 65, 68), (52, 60, 65, 68), (50,), (50,), (50,), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (54, 57, 62, 66), (45, 52, 55, 60, 64), (45, 52, 60, 64), (45, 52, 60, 64), (45, 52, 60, 64), (46, 56, 60, 65), (46, 56, 60, 65), (46, 56, 60, 65), (46, 56, 60, 65, 68), (48, 56, 57, 63, 67, 68, 71, 72), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (44, 54, 65, 70, 74), (46, 56, 60, 65), (46, 56, 60, 65), (46, 56, 60, 65, 68), (53, 56, 60, 63, 67, 68, 70, 72, 74, 82), (45, 52, 56, 57, 60, 64, 69), (45, 52, 56, 57, 60, 64, 69), (55, 60, 64, 71), (54, 55, 60, 64, 71, 72), (49, 57, 61, 64), (49, 57, 61, 64), (49, 57, 61, 64, 67), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68), (49, 59, 63, 68, 70), (49, 59, 63, 68, 70), (49, 59, 63, 68, 70), (49, 59, 63, 68, 70), (49, 59, 63, 68, 70), (59, 63, 70, 74), (59, 63, 70, 74), (59, 63, 70, 74), (59, 63, 70, 74), (59, 62, 63, 70, 74), (53, 59, 63), (53, 59, 63, 71), (43, 53, 59, 63, 71), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 57, 62, 67), (43, 52, 53, 57, 60, 62, 64, 67), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (32, 44, 56, 61, 63), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 57, 60, 64), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (32, 44, 56, 61, 63), (32, 44, 56, 61, 63), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (31, 43, 53, 57, 60, 64), (), (), (), (), (54, 60, 65, 80, 87, 92), (54, 60, 65, 80, 87, 92), (54, 60, 65, 80, 87, 92), (54, 60, 65, 80, 87, 92), (54, 60, 65, 80, 87, 92), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 79, 86, 91), (53, 59, 64, 78, 79, 85, 86, 90, 91), (), (), (59, 63, 83, 88, 91), (59, 63, 83, 88, 91), (59, 63, 83, 88, 91), (59, 63, 83, 88, 91), (59, 63, 83, 88, 91), (58, 62, 63, 67, 86, 91, 98), (), (58, 62, 63, 67, 86, 91, 98), (), (), (), (), (), (), (), (), (), (), (), (54, 60, 65, 77, 84, 89), (54, 60, 65, 77, 84, 89), (56, 60, 63, 67), (63, 67), (58, 62, 63, 67, 83, 95), (58, 62, 63, 67, 83, 95), (60, 64, 66, 71), (60, 64, 66, 71), (60, 64, 66, 71), (60, 64, 66, 71), (60, 64, 66, 71), (60, 64, 66, 71), (), (), (), (), (), (), (60, 66, 71), (60, 66, 71), (60, 66, 71), (60, 66, 71), (60, 66, 71), (60, 66, 71), (57, 61, 63), (57, 61, 63), (57, 61, 63), (57, 61, 63), (59, 60, 66), (59, 60), (59, 60), (54, 60, 65), (54, 60, 65), (54, 60, 65), (54, 60, 65), (54, 60, 65), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (), (), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 74, 81, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 64, 72, 74, 79, 81, 84, 86), (54, 60, 61, 64, 65, 72, 74, 79, 81, 84, 86), (54, 61, 65), (54, 56, 58, 61), (54, 58, 61, 66), (54, 58, 61, 68, 70), (58, 72), (), (79,), (79,), (79,), (79,), (), (74,), (), (), (), (), (), (), (79,), (), (80, 82), (80, 82), (53, 59, 75), (71,), (), (), (63,), (56, 59, 63), (56, 59, 63), (53, 56, 63), (63,), (), (67,), (67,), (), (), (53, 59, 64), (53, 59, 64), (53, 59, 64), (53,), (53,), (53,), (), (), (), (), (), (67,), (), (), (52, 55, 59, 62, 74), (52, 55, 59), (), (), (53, 59, 64, 76), (53, 77), (), (60, 65, 72), (60, 65, 72), (), (60, 65, 72), (), (), (), (60, 65, 72), (60, 65, 72), (60,), (57,), (), (60, 65, 72), (60, 65, 72), (), (), (50,), (50,), (50,), (50,), (47, 50, 56, 62), (47, 56, 59, 62), (47, 62), (), (72, 73, 76, 82, 84), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (69,), (62, 69), (), (), (), (), (), (), (), (), (), (), (), (), (61, 66, 70), (), (60, 65, 67), (60, 72), (), (), (61, 66, 70), (67,), (), (61, 66, 70), (), (), (), (57, 61, 66), (57, 61, 66), (57, 61, 66), (57, 61, 66), (57, 61, 66), (57, 61, 66), (57, 61, 66), (57, 61, 66), (), (), (), (), (), (), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (60, 65, 69), (65, 69), (65, 69), (65, 69), (65, 69), (65, 69), (65, 69), (65, 69), (65,), (64,), (64,), (64,), (), (), (65,), (65,), (65,), (64,), (64,), (64,), (64,), (64,), (64,), (64,), (64,), (), (), (), (), (64,), (64,), (64,), (64,), (64,), (64,), (64,), (64,), (64, 65), (), (60,), (), (60,), (60,), (), (), (), (60,), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (), (75,), (), (78,), (), (), (76,), (75,), (75,), (75,), (75,), (75,), (74,), (74,), (74,), (74,), (), (74,), (75,), (75,), (75,), (75,), (75,), (), (73,), (75,), (75,), (75,), (74,), (74,), (), (74,), (74,), (74,), (74,), (74,), (74,), (), (), (76,), (75,), (), (74,), (74,), (74,), (74,), (74,), (74,), (), (), (73,), (), (74,), (), (74,), (74,), (74,), (74,), (), (), (), (74,), (), (74,), (74,), (), (74,), (74,), (), (74,), (74,), (74,), (74,), (), (74,), (), (), (74,), (), (72,), (), (65,), (), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (62,), (63,), (64,), (62,), (62,), (62,), (62,), (63,), (64,), (64,), (62,), (), (64,), (64,), (63,), (), (60,), (60,), (60,), (61,), (61,), (57,), (57,), (), (60,), (61,), (62,), (62,), (63,), (59,), (55,), (55,), (54,), (60,), (60,), (62,), (60,), (), (59,), (), (), (), (60,), (60,), (60,), (60,), (59,), (), (), (), (), (), (), (), (), (60,), (), (), (), (), (62, 74), (), (), (), (64,), (64,), (64,), (), (62,), (62,), (62,), (62,), (), (), (), (64,), (64,), (64,), (64,), (64,), (), (), (63,), (64,), (64,), (60,), (60,), (60,), (60,), (60,), (), (62,), (64,), (65,), (62,), (62,), (), (), (), (62,), (62,), (62,), (62,), (62,), (62,), (), (62,), (), (62,), (62, 63), (60,), (62,), (), (62,), (62,), (62,), (63,), (63,), (64,), (64,), (60,), (60,), (60,), (64,), (62,), (62,), (62,), (), (), (), (60,), (), (64,), (64, 65), (), (), (), (), (64,), (), (), (), (61,), (61,), (64,), (), (), (62,), (), (), (59,), (), (), (), (61,), (), (64,), (64,), (62,), (), (), (), (), (), (61,), (), (), (57, 60), (60,), (), (), (), (59,), (61,), (), (), (60,), (), (59,), (), (61,), (), (), (), (), (61,), (), (), (), (), (), (61,), (), (), (), (), (59,), (59,), (59,), (59,), (), (62, 74), (), (), (64,), (), (), (), (67,), (67,), (), (), (62,), (62,), (62,), (62,), (62,), (62,), (), (), (), (62,), (), (60,), (61,), (63,), (), (), (62,), (60,), (), (), (), (59,), (), (64,), (64,), (62,), (64,), (64,), (64,), (), (), (64,), (64,), (64,), (), (62,), (62,), (62,), (62,), (60,), (62,), (63,), (60,), (60,), (), (), (), (), (), (), (), (), (), (60,), (61,), (61,), (61,), (), (61,), (61,), (), (60,), (), (63,), (), (64,), (), (), (), (64,), (), (64,), (), (57,), (58,), (57, 60), (57, 60), (60,), (60,), (), (57, 60), (57, 60), (), (60,), (), (), (60,), (60,), (60,), (), (62,), (60,), (), (), (), (), (), (), (), (59, 60), (), (), (), (), (), (), (62, 74), (62, 74), (62,), (63,), (), (), (), (), (61,), (61,), (), (), (), (), (), (), (60,), (), (), (), (), (76,), (76,), (), (), (), (), (72,), (), (), (), (), (), (), (), (), (), (), (), (), ()]\n",
            "-------------------------------------------\n",
            "[(42, 50, 57), (42, 50, 57, 62, 69), (42, 50, 57, 62, 69), (42, 50, 57, 62, 66, 69), (42, 50, 57, 62, 66, 69), (42, 50, 57, 62, 66, 69), (63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (60, 63, 67), (51, 57, 60, 63, 66), (51, 63, 66), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67), (52, 59, 62, 67, 69), (52, 59, 62, 67, 69), (55, 63, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71), (45, 55, 61, 63, 67, 71, 73), (45, 55, 61, 63, 67, 71, 73), (45, 55, 61, 63, 67, 71, 73), (62, 67, 74), (62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74), (50, 62, 67, 74, 86), (50, 62, 67, 74, 86), (50, 62, 67, 74, 86), (50, 62), (50, 62), (50, 62), (50,), '<UNK>', (50, 62, 80, 82, 86), (50, 62, 80, 82, 86), (50, 62, 74, 80, 82, 86), (50, 62, 74, 80, 82, 86), '<UNK>', (50,), (50,), (50, 62), (50,), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 79, 81, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), (50, 62, 74, 78, 80, 86), '<UNK>', (43, 49, 50, 62, 74, 78, 80, 86), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 59), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 76), (43, 50, 57, 59, 60, 62, 76), (43, 50, 57, 59, 60, 62, 76), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 57, 59, 60, 62, 76, 78), (43, 50, 55, 57, 59, 60, 62, 76, 78, 79), (43, 50, 55, 57, 59, 60, 62, 76, 78, 79), (43, 50, 55, 57, 59, 60, 61, 62, 64, 67, 70, 76, 78, 79), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76), (55, 61, 64, 67, 70, 76)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['<', '>', 'K', 'N', 'U'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "seed_len = 100\n",
        "num_note_to_gen = 1000\n",
        "\n",
        "song_idx = random.randint(0,len(all_song_tokenised)-1)\n",
        "seq_start_at = random.randint(0,len(all_song_tokenised[song_idx])-sequence_length)   \n",
        "start_tokens = all_song_tokenised[song_idx][seq_start_at:seq_start_at + seed_len].tolist()\n",
        "# start_tokens = inf_song[:seed_len]\n",
        "while (start_tokens == [()]*sequence_length):\n",
        "    print(\"Got all zeros, rerolling\")\n",
        "    song_idx = random.randint(0,len(all_song_tokenised)-1)\n",
        "    seq_start_at = random.randint(0,len(all_song_tokenised[song_idx])-sequence_length)   \n",
        "    start_tokens = all_song_tokenised[song_idx][seq_start_at:seq_start_at + sequence_length].tolist()\n",
        "    \n",
        "ori = start_tokens.copy()\n",
        "backup = ori.copy()\n",
        "# start_tokens = \n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "\n",
        "def sample_from(logits, k):\n",
        "    logits, indices = tf.math.top_k(logits, k= k, sorted=True)\n",
        "    indices = np.asarray(indices).astype(\"int32\")\n",
        "    preds = np.asarray(logits).astype(\"float32\")\n",
        "    if(unk_tag_idx in indices):\n",
        "        unk_tag_position = np.where(indices == unk_tag_idx)[0].item()\n",
        "        indices = np.delete(indices, unk_tag_position)\n",
        "        preds = np.delete(preds, unk_tag_position)\n",
        "    preds = softmax(preds)\n",
        "#     while out == 0:\n",
        "#         print(f\"predicted <UNK> tag with probability {preds[np.where(indices==0)[0][0]]}\")\n",
        "#         out = np.random.choice(indices, p=preds)\n",
        "    return np.random.choice(indices, p=preds)\n",
        "\n",
        "def convertToRoll(seq_list):\n",
        "#     a = network_input[start_idx].tolist()\n",
        "    seq_list = [int_to_combi[i] for i in seq_list]\n",
        "    roll = mlb.transform(seq_list)\n",
        "    print(seq_list)\n",
        "    return roll\n",
        "\n",
        "\n",
        "k = 10\n",
        "tokens_generated = []\n",
        "num_tokens_generated = 0\n",
        "\n",
        "while num_tokens_generated <= num_note_to_gen:\n",
        "\n",
        "    x = start_tokens[-sequence_length:]\n",
        "    pad_len = maxlen - len(start_tokens)\n",
        "    sample_index = -1\n",
        "    if pad_len > 0:\n",
        "        x = start_tokens + [0] * pad_len\n",
        "        sample_index = len(start_tokens) - 1\n",
        "    \n",
        "    x = np.array([x])\n",
        "    y, _ = model.predict(x)\n",
        "    sample_token = sample_from(y[0][sample_index], 10)\n",
        "    tokens_generated.append(sample_token)\n",
        "    start_tokens.append(sample_token)\n",
        "    num_tokens_generated = len(tokens_generated)\n",
        "    print(f\"generated {num_tokens_generated} notes\")\n",
        "    \n",
        "# print(f\"Piano int seq generated\")\n",
        "piano_roll = convertToRoll(start_tokens)\n",
        "print(\"-------------------------------------------\")\n",
        "ori = convertToRoll(ori)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpzPPNrq2yTZ"
      },
      "outputs": [],
      "source": [
        "def piano_roll_to_pretty_midi(piano_roll_in, fs, program=0, velocity = 64):\n",
        "    '''Convert a Piano Roll array into a PrettyMidi object\n",
        "     with a single instrument.\n",
        "    Parameters\n",
        "    ----------\n",
        "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
        "        Piano roll of one instrument\n",
        "    fs : int\n",
        "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
        "        by ``1./fs`` seconds.\n",
        "    program : int\n",
        "        The program number of the instrument.\n",
        "    Returns\n",
        "    -------\n",
        "    midi_object : pretty_midi.PrettyMIDI\n",
        "        A pretty_midi.PrettyMIDI class instance describing\n",
        "        the piano roll.\n",
        "    '''\n",
        "    piano_roll = np.where(piano_roll_in == 1, 64, 0)\n",
        "    notes, frames = piano_roll.shape\n",
        "    pm = pretty_midi.PrettyMIDI(initial_tempo=100.0)\n",
        "    instrument = pretty_midi.Instrument(program=program)\n",
        "\n",
        "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
        "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
        "    print(piano_roll.shape)\n",
        "    \n",
        "    # use changes in velocities to find note on / note off events\n",
        "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
        "\n",
        "    # keep track on velocities and note on times\n",
        "    prev_velocities = np.zeros(notes, dtype=int)\n",
        "    note_on_time = np.zeros(notes)\n",
        "\n",
        "    for time, note in zip(*velocity_changes):\n",
        "        # use time + 1 because of padding above\n",
        "        velocity = piano_roll[note, time + 1]\n",
        "        time = time / fs\n",
        "        if velocity > 0:\n",
        "            if prev_velocities[note] == 0:\n",
        "                note_on_time[note] = time\n",
        "                prev_velocities[note] = velocity\n",
        "        else:\n",
        "            pm_note = pretty_midi.Note(\n",
        "                velocity=prev_velocities[note],\n",
        "                pitch=note,\n",
        "                start=note_on_time[note],\n",
        "                end=time)\n",
        "            instrument.notes.append(pm_note)\n",
        "            prev_velocities[note] = 0\n",
        "    pm.instruments.append(instrument)\n",
        "    return pm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG7FKoyY2yTZ"
      },
      "source": [
        "## Export as MIDI\n",
        "Save the inference result to output folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4SPA2W02yTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7075000a-07e3-441b-ceb5-d9ca9961963b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 1103)\n",
            "(128, 102)\n"
          ]
        }
      ],
      "source": [
        "bpm = 150\n",
        "fs = 1/((60/bpm)/4)\n",
        "name = \"random2\"\n",
        "# fs = 100\n",
        "# ori = np.array(ori)\n",
        "mid_out = piano_roll_to_pretty_midi(piano_roll.T, fs=fs)\n",
        "mid_ori = piano_roll_to_pretty_midi(ori.T, fs=fs)\n",
        "midi_out_path = output_path+f\"gpt-v3-id-{name}.mid\"\n",
        "if midi_out_path is not None:\n",
        "        mid_out.write(midi_out_path)\n",
        "        \n",
        "midi_ori_path = output_path+f\"ori-gpt-v3-id-{name}.mid\"\n",
        "if midi_ori_path is not None:\n",
        "        mid_ori.write(midi_ori_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGCc1ezX2yTZ"
      },
      "source": [
        "Save full length of seed song for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODM4Uzf62yTa",
        "outputId": "3b1d7990-22e7-434f-cc85-f2cad5abd577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-94de56b231f8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ori_full = all_song_tokenised[song_idx][seq_start_at:].tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mori_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minf_song\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mori_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertToRoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mori_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiano_roll_to_pretty_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmidi_ori_full_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"orifull-gpt-v3-{name}.mid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inf_song' is not defined"
          ]
        }
      ],
      "source": [
        "# ori_full = all_song_tokenised[song_idx][seq_start_at:].tolist()\n",
        "ori_full = inf_song[:sequence_length+1000]\n",
        "ori_full = convertToRoll(ori_full)\n",
        "ori_full = piano_roll_to_pretty_midi(ori_full.T, fs=fs)\n",
        "midi_ori_full_path = output_path+f\"orifull-gpt-v3-{name}.mid\"\n",
        "if midi_ori_full_path is not None:\n",
        "        ori_full.write(midi_ori_full_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}